{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60655d9-913e-4f28-a7cb-acf008d1dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GEOparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    matthews_corrcoef,\n",
    "    make_scorer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d50a3d-2cf4-4f41-9a91-71429837b325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13-Jan-2026 15:47:11 DEBUG utils - Directory ../data already exists. Skipping.\n",
      "13-Jan-2026 15:47:11 INFO GEOparse - File already exist: using local version.\n",
      "13-Jan-2026 15:47:11 INFO GEOparse - Parsing ../data\\GSE68951_family.soft.gz: \n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - DATABASE: GeoMiame\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SERIES: GSE68951\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - PLATFORM: GPL16770\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688368\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688369\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688370\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688371\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688372\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688373\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688374\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688375\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688376\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688377\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688378\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688379\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688380\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688381\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688382\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688383\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688384\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688385\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688386\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688387\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688388\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688389\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688390\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688391\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688392\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688393\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688394\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688395\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688396\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688397\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688398\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688399\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688400\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688401\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688402\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688403\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688404\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688405\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688406\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688407\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688408\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688409\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688410\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688411\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688412\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688413\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688414\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688415\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688416\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688417\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688418\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688419\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688420\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688421\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688422\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688423\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688424\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688425\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688426\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688427\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688428\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688429\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688430\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688431\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688432\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688433\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688434\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688435\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688436\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688437\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688438\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688439\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688440\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688441\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688442\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688443\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688444\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688445\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688446\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688447\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688448\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688449\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688450\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688451\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688452\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688453\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688454\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688455\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688456\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688457\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688458\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688459\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688460\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688461\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688462\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688463\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688464\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688465\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688466\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688467\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688468\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688469\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688470\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688471\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688472\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688473\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688474\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688475\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688476\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688477\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688478\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688479\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688480\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688481\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688482\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688483\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688484\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688485\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688486\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688487\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688488\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688489\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688490\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688491\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688492\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688493\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688494\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688495\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688496\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688497\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688498\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688499\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688500\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688501\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688502\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688503\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688504\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688505\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688506\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688507\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688508\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688509\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688510\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688511\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688512\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688513\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688514\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688515\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688516\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688517\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688518\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688519\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688520\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688521\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688522\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688523\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688524\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688525\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688526\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688527\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688528\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688529\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688530\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688531\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688532\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688533\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688534\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688535\n",
      "13-Jan-2026 15:47:11 DEBUG GEOparse - SAMPLE: GSM1688536\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688537\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688538\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688539\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688540\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688541\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688542\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688543\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688544\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688545\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688546\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688547\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688548\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688549\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688550\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688551\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688552\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688553\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688554\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688555\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688556\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688557\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688558\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688559\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688560\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688561\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688562\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688563\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688564\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688565\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688566\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688567\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688568\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688569\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688570\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688571\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688572\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688573\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688574\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688575\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688576\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688577\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688578\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688579\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688580\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688581\n",
      "13-Jan-2026 15:47:12 DEBUG GEOparse - SAMPLE: GSM1688582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SERIES: GSE68951 - 215 SAMPLES, 1 d(s)>\n"
     ]
    }
   ],
   "source": [
    "gse = GEOparse.get_GEO(\"GSE68951\", destdir=\"../data\")\n",
    "print(gse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbcaee1-2a33-42ee-ae33-821c8b68aa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_REF</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>hsa-miR-100</td>\n",
       "      <td>1.936057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>hsa-miR-101</td>\n",
       "      <td>4.114362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>hsa-miR-1289</td>\n",
       "      <td>1.735477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>hsa-miR-1288</td>\n",
       "      <td>2.192123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>hsa-miR-105</td>\n",
       "      <td>1.285812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_REF     VALUE\n",
       "1200   hsa-miR-100  1.936057\n",
       "1201   hsa-miR-101  4.114362\n",
       "1202  hsa-miR-1289  1.735477\n",
       "1203  hsa-miR-1288  2.192123\n",
       "1204   hsa-miR-105  1.285812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = gse.gsms[\"GSM1688406\"]\n",
    "sample.table.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51533e9d-1569-42f5-89a8-70f6ea0de859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_full_info(gse):\n",
    "\n",
    "    data = [] \n",
    "    for gsm_id, sample in gse.gsms.items():\n",
    "\n",
    "        meta = sample.metadata[\"characteristics_ch1\"]\n",
    "\n",
    "        patient_id, timepoint, disease = None, None, None\n",
    "        \n",
    "        for item in meta:\n",
    "            if item.startswith(\"patient id\"):\n",
    "                patient_id = item.split(\":\")[1].strip()\n",
    "            if item.startswith(\"timepoint\"):\n",
    "                timepoint = int(item.split(\":\")[1].strip())\n",
    "            if item.startswith(\"disease\"):\n",
    "                disease = item.split(\":\")[1].strip()\n",
    "        if patient_id is None or timepoint is None:\n",
    "            continue\n",
    "\n",
    "        mirnas = sample.table[\"ID_REF\"].values\n",
    "        expr   = sample.table[\"VALUE\"].values.astype(float)\n",
    "\n",
    "        data.append({\n",
    "            \"gsm\": gsm_id,\n",
    "            \"patient\": patient_id,\n",
    "            \"timepoint\": timepoint,\n",
    "            \"mirna_names\": mirnas,\n",
    "            \"expression\": expr\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a73a131-6462-4652-bfb2-e5768816272d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gsm</th>\n",
       "      <th>patient</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>mirna_names</th>\n",
       "      <th>expression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM1688368</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>[hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...</td>\n",
       "      <td>[1.854979099, 2.184182338, 2.532296403, 1.5180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM1688369</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...</td>\n",
       "      <td>[1.469763084, 2.320244044, 2.111889095, 1.6172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM1688370</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>[hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...</td>\n",
       "      <td>[1.44937518, 2.510284729, 2.083508284, 1.23588...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM1688371</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>[hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...</td>\n",
       "      <td>[1.777522456, 2.724678628, 3.012721615, 1.3907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM1688372</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>[hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...</td>\n",
       "      <td>[1.538218176, 2.030509973, 2.470374907, 1.5635...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gsm patient  timepoint  \\\n",
       "0  GSM1688368       A          1   \n",
       "1  GSM1688369       A          2   \n",
       "2  GSM1688370       A          3   \n",
       "3  GSM1688371       A          4   \n",
       "4  GSM1688372       A          5   \n",
       "\n",
       "                                         mirna_names  \\\n",
       "0  [hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...   \n",
       "1  [hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...   \n",
       "2  [hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...   \n",
       "3  [hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...   \n",
       "4  [hsa-miR-507, hsa-miR-548d-5p, hsa-miR-1976, h...   \n",
       "\n",
       "                                          expression  \n",
       "0  [1.854979099, 2.184182338, 2.532296403, 1.5180...  \n",
       "1  [1.469763084, 2.320244044, 2.111889095, 1.6172...  \n",
       "2  [1.44937518, 2.510284729, 2.083508284, 1.23588...  \n",
       "3  [1.777522456, 2.724678628, 3.012721615, 1.3907...  \n",
       "4  [1.538218176, 2.030509973, 2.470374907, 1.5635...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = extract_full_info(gse)\n",
    "df_all.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d7eb549-2fe6-4768-8cf8-13f945c95cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix\n",
    "X = np.vstack(df_all[\"expression\"].values)\n",
    "\n",
    "# Labels = patient identity\n",
    "y = df_all[\"patient\"].astype(\"category\").cat.codes.values\n",
    "\n",
    "# Groups = patient (CV kontrolü için)\n",
    "groups = df_all[\"patient\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42cb7368-1c8b-4ad9-a2f2-7c47eaa4621b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient\n",
       "A              8\n",
       "B              8\n",
       "C              8\n",
       "D              8\n",
       "E              8\n",
       "F              8\n",
       "G              8\n",
       "H              7\n",
       "I              8\n",
       "J              8\n",
       "K              8\n",
       "L              8\n",
       "M              8\n",
       "N              8\n",
       "O              8\n",
       "P              8\n",
       "Q              8\n",
       "R              8\n",
       "S              7\n",
       "T              8\n",
       "U              8\n",
       "V              8\n",
       "W              8\n",
       "X              7\n",
       "Y              8\n",
       "Z              6\n",
       "ZZ_control    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.groupby(\"patient\").size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d6f0f90-a0ae-4850-ab7d-d5bd8d7f2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_classifier = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=5000)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f651154-e2f4-4460-966f-f946921ccf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_logreg(X, y, classifier=None):\n",
    "\n",
    "    if classifier is None:\n",
    "        classifier = LogisticRegression(max_iter=5000)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277ac188-daf3-42ee-96e8-c502e05e5c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.33      0.50      0.40         2\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.33      0.50      0.40         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.50      0.50      0.50         2\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.50      0.50      0.50         2\n",
      "          19       0.00      0.00      0.00         3\n",
      "          20       0.00      0.00      0.00         2\n",
      "          21       0.50      0.33      0.40         3\n",
      "          22       0.33      0.67      0.44         3\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      0.50      0.67         2\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.23        65\n",
      "   macro avg       0.25      0.24      0.23        65\n",
      "weighted avg       0.25      0.23      0.23        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = evaluate_model_logreg(X, y, scaler_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3e792f-4bd5-4933-b67d-ba382634796f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'D',\n",
       "       'D', 'D', 'D', 'D', 'D', 'D', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "       'E', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'G', 'G', 'G', 'G',\n",
       "       'G', 'G', 'G', 'G', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'I', 'I',\n",
       "       'I', 'I', 'I', 'I', 'I', 'I', 'J', 'J', 'J', 'J', 'J', 'J', 'J',\n",
       "       'J', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'L', 'L', 'L', 'L',\n",
       "       'L', 'L', 'L', 'L', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'N',\n",
       "       'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'Q', 'Q', 'Q',\n",
       "       'Q', 'Q', 'Q', 'Q', 'Q', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'T', 'T', 'T', 'T', 'T', 'T',\n",
       "       'T', 'T', 'U', 'U', 'U', 'U', 'U', 'U', 'U', 'U', 'V', 'V', 'V',\n",
       "       'V', 'V', 'V', 'V', 'V', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W',\n",
       "       'X', 'X', 'X', 'X', 'X', 'X', 'X', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n",
       "       'Y', 'Y', 'Z', 'Z', 'Z', 'Z', 'Z', 'Z', 'ZZ_control', 'ZZ_control',\n",
       "       'ZZ_control', 'ZZ_control', 'ZZ_control', 'ZZ_control',\n",
       "       'ZZ_control', 'ZZ_control', 'ZZ_control', 'ZZ_control',\n",
       "       'ZZ_control', 'ZZ_control'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3520f11-4570-4037-97eb-27a1d48f57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_logreg_groupKFold(X, y, groups):\n",
    "\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    fold = 1\n",
    "\n",
    "    clf = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(max_iter=5000)\n",
    "    )\n",
    "\n",
    "    for train_idx, test_idx in gkf.split(X, y, groups):\n",
    "\n",
    "        print(f\"\\n====== Fold {fold} ======\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"F1 macro:\", f1)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        f1s.append(f1)\n",
    "        fold += 1\n",
    "\n",
    "    print(\"\\n=== FINAL LOGREG ===\")\n",
    "    print(\"Mean Accuracy:\", np.mean(accuracies))\n",
    "    print(\"Mean F1 Macro:\", np.mean(f1s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d34435-adf6-49fd-9375-b02bc23ea01a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Fold 1 ======\n",
      "Accuracy: 0.0\n",
      "F1 macro: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00       8.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           7       0.00      0.00      0.00       0.0\n",
      "          11       0.00      0.00      0.00       0.0\n",
      "          12       0.00      0.00      0.00       8.0\n",
      "          13       0.00      0.00      0.00       0.0\n",
      "          14       0.00      0.00      0.00       8.0\n",
      "          17       0.00      0.00      0.00       0.0\n",
      "          18       0.00      0.00      0.00       7.0\n",
      "          19       0.00      0.00      0.00       0.0\n",
      "          21       0.00      0.00      0.00       0.0\n",
      "          22       0.00      0.00      0.00       0.0\n",
      "          24       0.00      0.00      0.00       0.0\n",
      "          26       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      43.0\n",
      "   macro avg       0.00      0.00      0.00      43.0\n",
      "weighted avg       0.00      0.00      0.00      43.0\n",
      "\n",
      "\n",
      "====== Fold 2 ======\n",
      "Accuracy: 0.0\n",
      "F1 macro: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       8.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           5       0.00      0.00      0.00       0.0\n",
      "           7       0.00      0.00      0.00       0.0\n",
      "           9       0.00      0.00      0.00       0.0\n",
      "          10       0.00      0.00      0.00       0.0\n",
      "          11       0.00      0.00      0.00       8.0\n",
      "          12       0.00      0.00      0.00       0.0\n",
      "          15       0.00      0.00      0.00       8.0\n",
      "          16       0.00      0.00      0.00       0.0\n",
      "          17       0.00      0.00      0.00       0.0\n",
      "          20       0.00      0.00      0.00       8.0\n",
      "          21       0.00      0.00      0.00       0.0\n",
      "          22       0.00      0.00      0.00       0.0\n",
      "          24       0.00      0.00      0.00       8.0\n",
      "          25       0.00      0.00      0.00       6.0\n",
      "\n",
      "    accuracy                           0.00      46.0\n",
      "   macro avg       0.00      0.00      0.00      46.0\n",
      "weighted avg       0.00      0.00      0.00      46.0\n",
      "\n",
      "\n",
      "====== Fold 3 ======\n",
      "Accuracy: 0.0\n",
      "F1 macro: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       8.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           3       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           6       0.00      0.00      0.00       8.0\n",
      "           7       0.00      0.00      0.00       0.0\n",
      "           8       0.00      0.00      0.00       0.0\n",
      "           9       0.00      0.00      0.00       0.0\n",
      "          10       0.00      0.00      0.00       8.0\n",
      "          11       0.00      0.00      0.00       0.0\n",
      "          13       0.00      0.00      0.00       0.0\n",
      "          14       0.00      0.00      0.00       0.0\n",
      "          17       0.00      0.00      0.00       0.0\n",
      "          18       0.00      0.00      0.00       0.0\n",
      "          19       0.00      0.00      0.00       8.0\n",
      "          20       0.00      0.00      0.00       0.0\n",
      "          22       0.00      0.00      0.00       8.0\n",
      "          25       0.00      0.00      0.00       0.0\n",
      "          26       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      40.0\n",
      "   macro avg       0.00      0.00      0.00      40.0\n",
      "weighted avg       0.00      0.00      0.00      40.0\n",
      "\n",
      "\n",
      "====== Fold 4 ======\n",
      "Accuracy: 0.0\n",
      "F1 macro: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           3       0.00      0.00      0.00       8.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           5       0.00      0.00      0.00       8.0\n",
      "           9       0.00      0.00      0.00       8.0\n",
      "          13       0.00      0.00      0.00       0.0\n",
      "          15       0.00      0.00      0.00       0.0\n",
      "          16       0.00      0.00      0.00       8.0\n",
      "          17       0.00      0.00      0.00       8.0\n",
      "          18       0.00      0.00      0.00       0.0\n",
      "          20       0.00      0.00      0.00       0.0\n",
      "          22       0.00      0.00      0.00       0.0\n",
      "          25       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      40.0\n",
      "   macro avg       0.00      0.00      0.00      40.0\n",
      "weighted avg       0.00      0.00      0.00      40.0\n",
      "\n",
      "\n",
      "====== Fold 5 ======\n",
      "Accuracy: 0.0\n",
      "F1 macro: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       8.0\n",
      "           6       0.00      0.00      0.00       0.0\n",
      "           7       0.00      0.00      0.00       7.0\n",
      "           8       0.00      0.00      0.00       8.0\n",
      "           9       0.00      0.00      0.00       0.0\n",
      "          10       0.00      0.00      0.00       0.0\n",
      "          11       0.00      0.00      0.00       0.0\n",
      "          12       0.00      0.00      0.00       0.0\n",
      "          13       0.00      0.00      0.00       8.0\n",
      "          15       0.00      0.00      0.00       0.0\n",
      "          17       0.00      0.00      0.00       0.0\n",
      "          18       0.00      0.00      0.00       0.0\n",
      "          19       0.00      0.00      0.00       0.0\n",
      "          21       0.00      0.00      0.00       8.0\n",
      "          22       0.00      0.00      0.00       0.0\n",
      "          23       0.00      0.00      0.00       7.0\n",
      "          25       0.00      0.00      0.00       0.0\n",
      "          26       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      46.0\n",
      "   macro avg       0.00      0.00      0.00      46.0\n",
      "weighted avg       0.00      0.00      0.00      46.0\n",
      "\n",
      "\n",
      "=== FINAL LOGREG ===\n",
      "Mean Accuracy: 0.0\n",
      "Mean F1 Macro: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.8549791 , 2.18418234, 2.5322964 , ..., 1.41000193, 3.72745529,\n",
       "         1.37007761],\n",
       "        [1.46976308, 2.32024404, 2.11188909, ..., 1.4279172 , 2.45035886,\n",
       "         1.35776645],\n",
       "        [1.44937518, 2.51028473, 2.08350828, ..., 1.12366167, 2.571076  ,\n",
       "         1.06683767],\n",
       "        ...,\n",
       "        [1.55135439, 2.09630509, 1.84061179, ..., 1.46840623, 4.03715339,\n",
       "         0.933782  ],\n",
       "        [1.58819243, 2.44854081, 2.43935147, ..., 1.26001547, 3.43739097,\n",
       "         1.32423004],\n",
       "        [1.96891928, 2.30610466, 2.02487855, ..., 1.21281883, 3.98844345,\n",
       "         0.86618795]], shape=(215, 1205)),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21,\n",
       "        21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23,\n",
       "        23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 26,\n",
       "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26], dtype=int8),\n",
       " array(['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B',\n",
       "        'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'D',\n",
       "        'D', 'D', 'D', 'D', 'D', 'D', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
       "        'E', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'G', 'G', 'G', 'G',\n",
       "        'G', 'G', 'G', 'G', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'I', 'I',\n",
       "        'I', 'I', 'I', 'I', 'I', 'I', 'J', 'J', 'J', 'J', 'J', 'J', 'J',\n",
       "        'J', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'L', 'L', 'L', 'L',\n",
       "        'L', 'L', 'L', 'L', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'N',\n",
       "        'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "        'O', 'O', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'Q', 'Q', 'Q',\n",
       "        'Q', 'Q', 'Q', 'Q', 'Q', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "        'S', 'S', 'S', 'S', 'S', 'S', 'S', 'T', 'T', 'T', 'T', 'T', 'T',\n",
       "        'T', 'T', 'U', 'U', 'U', 'U', 'U', 'U', 'U', 'U', 'V', 'V', 'V',\n",
       "        'V', 'V', 'V', 'V', 'V', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W',\n",
       "        'X', 'X', 'X', 'X', 'X', 'X', 'X', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n",
       "        'Y', 'Y', 'Z', 'Z', 'Z', 'Z', 'Z', 'Z', 'ZZ_control', 'ZZ_control',\n",
       "        'ZZ_control', 'ZZ_control', 'ZZ_control', 'ZZ_control',\n",
       "        'ZZ_control', 'ZZ_control', 'ZZ_control', 'ZZ_control',\n",
       "        'ZZ_control', 'ZZ_control'], dtype=object))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_logreg_groupKFold(X, y, groups)\n",
    "(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bacfa027-5187-4afb-8e47-c1741071a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svm_pca_pipeline():\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA()),\n",
    "        (\"svm\", SVC(kernel=\"rbf\"))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da77806b-253c-406f-8adb-bb7a34f6952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(pipeline, X, y, groups):\n",
    "\n",
    "    param_grid = {\n",
    "        \"pca__n_components\": [5, 10, 15, 20],\n",
    "        \"svm__C\": [0.1, 1, 10],\n",
    "        \"svm__gamma\": [\"scale\", 0.01, 0.001]\n",
    "    }\n",
    "\n",
    "    mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        scoring=mcc_scorer,\n",
    "        cv=gkf.split(X, y, groups),\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    print(\"Best Params:\", grid.best_params_)\n",
    "    print(\"Best MCC:\", grid.best_score_)\n",
    "\n",
    "    return grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d15c0172-aa1d-49c3-9803-6bcdd2f4b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, groups):\n",
    "\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    fold = 1\n",
    "\n",
    "    for train_idx, test_idx in gkf.split(X, y, groups):\n",
    "\n",
    "        print(f\"\\n====== Fold {fold} ======\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"F1:\", f1)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        f1s.append(f1)\n",
    "        fold += 1\n",
    "\n",
    "    print(\"\\nFINAL RESULTS\")\n",
    "    print(\"Mean Accuracy:\", np.mean(accuracies))\n",
    "    print(\"Mean F1 Macro:\", np.mean(f1s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b30ee89a-3a79-4dd8-843f-49ffb9609bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_pca_experiment(X, y, groups):\n",
    "\n",
    "    print(\"Building model\")\n",
    "    pipeline = build_svm_pca_pipeline()\n",
    "\n",
    "    print(\"Tuning hyperparameters\")\n",
    "    best_model = tune_hyperparameters(pipeline, X, y, groups)\n",
    "\n",
    "    print(\"Evaluating final model\")\n",
    "    evaluate_model(best_model, X, y, groups)\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0663cd20-ff65-43c3-9ef2-09bd07f83e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model\n",
      "Tuning hyperparameters\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Params: {'pca__n_components': 5, 'svm__C': 0.1, 'svm__gamma': 'scale'}\n",
      "Best MCC: 0.0\n",
      "Evaluating final model\n",
      "\n",
      "====== Fold 1 ======\n",
      "Accuracy: 0.0\n",
      "F1: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00       8.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           5       0.00      0.00      0.00       0.0\n",
      "           8       0.00      0.00      0.00       0.0\n",
      "           9       0.00      0.00      0.00       0.0\n",
      "          10       0.00      0.00      0.00       0.0\n",
      "          11       0.00      0.00      0.00       0.0\n",
      "          12       0.00      0.00      0.00       8.0\n",
      "          13       0.00      0.00      0.00       0.0\n",
      "          14       0.00      0.00      0.00       8.0\n",
      "          16       0.00      0.00      0.00       0.0\n",
      "          17       0.00      0.00      0.00       0.0\n",
      "          18       0.00      0.00      0.00       7.0\n",
      "          19       0.00      0.00      0.00       0.0\n",
      "          21       0.00      0.00      0.00       0.0\n",
      "          26       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      43.0\n",
      "   macro avg       0.00      0.00      0.00      43.0\n",
      "weighted avg       0.00      0.00      0.00      43.0\n",
      "\n",
      "\n",
      "====== Fold 2 ======\n",
      "Accuracy: 0.0\n",
      "F1: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00       8.0\n",
      "          11       0.00      0.00      0.00       8.0\n",
      "          15       0.00      0.00      0.00       8.0\n",
      "          20       0.00      0.00      0.00       8.0\n",
      "          24       0.00      0.00      0.00       8.0\n",
      "          25       0.00      0.00      0.00       6.0\n",
      "          26       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      46.0\n",
      "   macro avg       0.00      0.00      0.00      46.0\n",
      "weighted avg       0.00      0.00      0.00      46.0\n",
      "\n",
      "\n",
      "====== Fold 3 ======\n",
      "Accuracy: 0.0\n",
      "F1: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       8.0\n",
      "           6       0.00      0.00      0.00       8.0\n",
      "          10       0.00      0.00      0.00       8.0\n",
      "          19       0.00      0.00      0.00       8.0\n",
      "          22       0.00      0.00      0.00       8.0\n",
      "          26       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      40.0\n",
      "   macro avg       0.00      0.00      0.00      40.0\n",
      "weighted avg       0.00      0.00      0.00      40.0\n",
      "\n",
      "\n",
      "====== Fold 4 ======\n",
      "Accuracy: 0.0\n",
      "F1: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00       8.0\n",
      "           5       0.00      0.00      0.00       8.0\n",
      "           9       0.00      0.00      0.00       8.0\n",
      "          16       0.00      0.00      0.00       8.0\n",
      "          17       0.00      0.00      0.00       8.0\n",
      "          26       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      40.0\n",
      "   macro avg       0.00      0.00      0.00      40.0\n",
      "weighted avg       0.00      0.00      0.00      40.0\n",
      "\n",
      "\n",
      "====== Fold 5 ======\n",
      "Accuracy: 0.0\n",
      "F1: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00       8.0\n",
      "           7       0.00      0.00      0.00       7.0\n",
      "           8       0.00      0.00      0.00       8.0\n",
      "          13       0.00      0.00      0.00       8.0\n",
      "          21       0.00      0.00      0.00       8.0\n",
      "          23       0.00      0.00      0.00       7.0\n",
      "          26       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      46.0\n",
      "   macro avg       0.00      0.00      0.00      46.0\n",
      "weighted avg       0.00      0.00      0.00      46.0\n",
      "\n",
      "\n",
      "FINAL RESULTS\n",
      "Mean Accuracy: 0.0\n",
      "Mean F1 Macro: 0.0\n"
     ]
    }
   ],
   "source": [
    "best_model = run_svm_pca_experiment(X, y, groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df4e5c5f-2e62-49b9-9440-712424b1e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import GEOparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    matthews_corrcoef,\n",
    "    make_scorer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6319a02-485d-4e38-a60c-b27c5a486c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df_all.groupby(\"patient\")\n",
    "first = next(iter(g))\n",
    "type(first), len(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b7e8bc-8715-40b4-9baa-14fa7178ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reidentification_cv(df):\n",
    "    for patient, df_p in df.groupby(\"patient\"):\n",
    "        for test_idx in df_p.index:\n",
    "            train_idx = df.index.difference([test_idx])\n",
    "            yield train_idx.to_numpy(), np.array([test_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43c7b82f-e12a-4f89-ad28-3894f19aee67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.488372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.583243</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.508338</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.588592</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.511669</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.000000  0.000000  0.000000    8.000000\n",
       "1              0.214286  0.375000  0.272727    8.000000\n",
       "2              0.411765  0.875000  0.560000    8.000000\n",
       "3              0.750000  0.375000  0.500000    8.000000\n",
       "4              0.500000  0.250000  0.333333    8.000000\n",
       "5              0.600000  0.750000  0.666667    8.000000\n",
       "6              0.400000  0.250000  0.307692    8.000000\n",
       "7              0.600000  0.428571  0.500000    7.000000\n",
       "8              0.600000  0.375000  0.461538    8.000000\n",
       "9              0.714286  0.625000  0.666667    8.000000\n",
       "10             0.500000  0.125000  0.200000    8.000000\n",
       "11             0.333333  0.375000  0.352941    8.000000\n",
       "12             1.000000  0.375000  0.545455    8.000000\n",
       "13             0.400000  0.500000  0.444444    8.000000\n",
       "14             1.000000  0.750000  0.857143    8.000000\n",
       "15             0.500000  0.375000  0.428571    8.000000\n",
       "16             0.500000  0.375000  0.428571    8.000000\n",
       "17             0.384615  0.625000  0.476190    8.000000\n",
       "18             0.833333  0.714286  0.769231    7.000000\n",
       "19             0.857143  0.750000  0.800000    8.000000\n",
       "20             0.750000  0.375000  0.500000    8.000000\n",
       "21             0.625000  0.625000  0.625000    8.000000\n",
       "22             0.666667  0.750000  0.705882    8.000000\n",
       "23             1.000000  0.857143  0.923077    7.000000\n",
       "24             0.857143  0.750000  0.800000    8.000000\n",
       "25             0.000000  0.000000  0.000000    6.000000\n",
       "26             0.750000  0.500000  0.600000   12.000000\n",
       "accuracy       0.488372  0.488372  0.488372    0.488372\n",
       "macro avg      0.583243  0.486111  0.508338  215.000000\n",
       "weighted avg   0.588592  0.488372  0.511669  215.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=0.9)),  # %90 variance\n",
    "    (\"logreg\", LogisticRegression(max_iter=5000))\n",
    "])\n",
    "\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(reidentification_cv(df_all), 1):\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    y_true_all.extend(y_test)\n",
    "    y_pred_all.extend(y_pred)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true_all,\n",
    "    y_pred_all,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8be72bb-9c16-420a-b407-b5dbd469be44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.409302</td>\n",
       "      <td>0.409302</td>\n",
       "      <td>0.409302</td>\n",
       "      <td>0.409302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.468396</td>\n",
       "      <td>0.405864</td>\n",
       "      <td>0.400535</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.472073</td>\n",
       "      <td>0.409302</td>\n",
       "      <td>0.404468</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.050000  0.125000  0.071429    8.000000\n",
       "1              0.235294  0.500000  0.320000    8.000000\n",
       "2              0.384615  0.625000  0.476190    8.000000\n",
       "3              0.600000  0.375000  0.461538    8.000000\n",
       "4              1.000000  0.125000  0.222222    8.000000\n",
       "5              0.666667  0.750000  0.705882    8.000000\n",
       "6              0.000000  0.000000  0.000000    8.000000\n",
       "7              0.400000  0.285714  0.333333    7.000000\n",
       "8              0.000000  0.000000  0.000000    8.000000\n",
       "9              0.428571  0.375000  0.400000    8.000000\n",
       "10             0.222222  0.250000  0.235294    8.000000\n",
       "11             0.312500  0.625000  0.416667    8.000000\n",
       "12             0.500000  0.125000  0.200000    8.000000\n",
       "13             0.666667  0.500000  0.571429    8.000000\n",
       "14             1.000000  0.625000  0.769231    8.000000\n",
       "15             0.222222  0.250000  0.235294    8.000000\n",
       "16             0.250000  0.125000  0.166667    8.000000\n",
       "17             0.285714  0.750000  0.413793    8.000000\n",
       "18             0.833333  0.714286  0.769231    7.000000\n",
       "19             0.333333  0.250000  0.285714    8.000000\n",
       "20             0.200000  0.125000  0.153846    8.000000\n",
       "21             0.666667  0.750000  0.705882    8.000000\n",
       "22             0.500000  0.625000  0.555556    8.000000\n",
       "23             1.000000  1.000000  1.000000    7.000000\n",
       "24             0.500000  0.250000  0.333333    8.000000\n",
       "25             0.500000  0.166667  0.250000    6.000000\n",
       "26             0.888889  0.666667  0.761905   12.000000\n",
       "accuracy       0.409302  0.409302  0.409302    0.409302\n",
       "macro avg      0.468396  0.405864  0.400535  215.000000\n",
       "weighted avg   0.472073  0.409302  0.404468  215.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=0.9)),\n",
    "    (\"svm\", SVC(\n",
    "        kernel=\"rbf\",\n",
    "        C=10,\n",
    "        gamma=\"scale\",\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "y_true_all_svm = []\n",
    "y_pred_all_svm = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(reidentification_cv(df_all), 1):\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    clf_svm.fit(X_train, y_train)\n",
    "    y_pred = clf_svm.predict(X_test)\n",
    "\n",
    "    y_true_all_svm.extend(y_test)\n",
    "    y_pred_all_svm.extend(y_pred)\n",
    "\n",
    "report_svm = classification_report(\n",
    "    y_true_all_svm,\n",
    "    y_pred_all_svm,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "report_svm_df = pd.DataFrame(report_svm).transpose()\n",
    "report_svm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bab04b0c-79ab-4f4e-95fd-57da093b890e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogReg_precision</th>\n",
       "      <th>LogReg_recall</th>\n",
       "      <th>LogReg_f1</th>\n",
       "      <th>SVM_precision</th>\n",
       "      <th>SVM_recall</th>\n",
       "      <th>SVM_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.583243</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.508338</td>\n",
       "      <td>0.468396</td>\n",
       "      <td>0.405864</td>\n",
       "      <td>0.400535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LogReg_precision  LogReg_recall  LogReg_f1  SVM_precision  \\\n",
       "macro avg          0.583243       0.486111   0.508338       0.468396   \n",
       "\n",
       "           SVM_recall    SVM_f1  \n",
       "macro avg    0.405864  0.400535  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"LogReg_precision\": report_df.loc[\"macro avg\", \"precision\"],\n",
    "    \"LogReg_recall\": report_df.loc[\"macro avg\", \"recall\"],\n",
    "    \"LogReg_f1\": report_df.loc[\"macro avg\", \"f1-score\"],\n",
    "    \"SVM_precision\": report_svm_df.loc[\"macro avg\", \"precision\"],\n",
    "    \"SVM_recall\": report_svm_df.loc[\"macro avg\", \"recall\"],\n",
    "    \"SVM_f1\": report_svm_df.loc[\"macro avg\", \"f1-score\"],\n",
    "}, index=[\"macro avg\"])\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37400ef9-92f0-47ab-b186-0f69c12f6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_positive_pairs(X, y):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    for patient in np.unique(y):\n",
    "        idx = np.where(y == patient)[0]\n",
    "        for i in range(len(idx)):\n",
    "            for j in range(i + 1, len(idx)):\n",
    "                pairs.append([X[idx[i]], X[idx[j]]])\n",
    "                labels.append(1)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f37227df-b855-4455-a9c8-af37b4ae9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_negative_pairs(X, y, n_pairs):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    patients = np.unique(y)\n",
    "\n",
    "    for _ in range(n_pairs):\n",
    "        p1, p2 = np.random.choice(patients, 2, replace=False) #random negative sampling\n",
    "        i = np.random.choice(np.where(y == p1)[0])\n",
    "        j = np.random.choice(np.where(y == p2)[0])\n",
    "\n",
    "        pairs.append([X[i], X[j]])\n",
    "        labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf0ddcd-363d-444d-9ff4-294920f114e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp, yp = make_positive_pairs(X_train, y_train)\n",
    "Xn, yn = make_negative_pairs(X_train, y_train, len(yp))\n",
    "\n",
    "X_pairs = np.vstack([Xp, Xn]) #forms a 3D tensor\n",
    "y_pairs = np.hstack([yp, yn])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c938d28-af0e-4112-8858-d68b661023f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cihan\\ki-al-miRNA-attack\\venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def build_base_network(input_dim):\n",
    "    inp = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(128, activation=\"relu\")(inp)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    return Model(inp, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2045afae-9e72-4ea7-864a-7afd43b4364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cihan\\ki-al-miRNA-attack\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = X.shape[1]\n",
    "base = build_base_network(input_dim)\n",
    "\n",
    "input_a = layers.Input(shape=(input_dim,))\n",
    "input_b = layers.Input(shape=(input_dim,))\n",
    "\n",
    "emb_a = base(input_a)\n",
    "emb_b = base(input_b)\n",
    "\n",
    "distance = layers.Lambda(\n",
    "    lambda x: tf.reduce_sum(tf.square(x[0] - x[1]), axis=1, keepdims=True)\n",
    ")([emb_a, emb_b])\n",
    "\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "siamese = Model([input_a, input_b], output)\n",
    "siamese.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b9ef68f-bb04-4a08-ab34-34e869af9e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2493a91ec30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese.fit(\n",
    "    [X_pairs[:,0], X_pairs[:,1]],\n",
    "    y_pairs,\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "832113ca-9374-4d94-9e45-520743d06aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_patient_siamese(siamese, x_test, X_train, y_train):\n",
    "    scores = []\n",
    "\n",
    "    for x_tr, patient in zip(X_train, y_train):\n",
    "        prob = siamese.predict(\n",
    "            [x_test.reshape(1,-1), x_tr.reshape(1,-1)],\n",
    "            verbose=0\n",
    "        )[0][0]\n",
    "        scores.append((patient, prob))\n",
    "\n",
    "    df_scores = pd.DataFrame(scores, columns=[\"patient\", \"score\"])\n",
    "    return df_scores.groupby(\"patient\")[\"score\"].mean().idxmax() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2261858d-f787-4198-9ac4-c39dfaa33422",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for train_idx, test_idx in reidentification_cv(df_all):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # pair üret, train et (yukarıdaki adımlar)\n",
    "    # sonra predict_patient_siamese\n",
    "\n",
    "    y_pred = predict_patient_siamese(\n",
    "        siamese, X_test[0], X_train, y_train\n",
    "    )\n",
    "\n",
    "    y_true_all.append(y_test[0])\n",
    "    y_pred_all.append(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fe94847-0cee-4ba9-928d-e56630083f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING:\n",
    "# At this stage, the model is NOT reset between folds.\n",
    "# This introduces data leakage and leads to overly optimistic results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a95c190d-117a-4bab-8b64-f2459c40da82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.058252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>12.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.07907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.113269</td>\n",
       "      <td>0.060185</td>\n",
       "      <td>0.041938</td>\n",
       "      <td>215.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.114879</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.044181</td>\n",
       "      <td>215.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.000000  0.000000  0.000000    8.00000\n",
       "1              0.000000  0.000000  0.000000    8.00000\n",
       "2              0.000000  0.000000  0.000000    8.00000\n",
       "3              0.000000  0.000000  0.000000    8.00000\n",
       "4              0.000000  0.000000  0.000000    8.00000\n",
       "5              0.000000  0.000000  0.000000    8.00000\n",
       "6              0.000000  0.000000  0.000000    8.00000\n",
       "7              0.000000  0.000000  0.000000    7.00000\n",
       "8              0.000000  0.000000  0.000000    8.00000\n",
       "9              0.000000  0.000000  0.000000    8.00000\n",
       "10             0.000000  0.000000  0.000000    8.00000\n",
       "11             0.000000  0.000000  0.000000    8.00000\n",
       "12             0.000000  0.000000  0.000000    8.00000\n",
       "13             0.000000  0.000000  0.000000    8.00000\n",
       "14             0.000000  0.000000  0.000000    8.00000\n",
       "15             0.500000  0.125000  0.200000    8.00000\n",
       "16             0.000000  0.000000  0.000000    8.00000\n",
       "17             1.000000  0.250000  0.400000    8.00000\n",
       "18             0.000000  0.000000  0.000000    7.00000\n",
       "19             0.500000  0.125000  0.200000    8.00000\n",
       "20             0.000000  0.000000  0.000000    8.00000\n",
       "21             1.000000  0.125000  0.222222    8.00000\n",
       "22             0.000000  0.000000  0.000000    8.00000\n",
       "23             0.000000  0.000000  0.000000    7.00000\n",
       "24             0.000000  0.000000  0.000000    8.00000\n",
       "25             0.000000  0.000000  0.000000    6.00000\n",
       "26             0.058252  1.000000  0.110092   12.00000\n",
       "accuracy       0.079070  0.079070  0.079070    0.07907\n",
       "macro avg      0.113269  0.060185  0.041938  215.00000\n",
       "weighted avg   0.114879  0.079070  0.044181  215.00000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(reidentification_cv(df_all), 1):\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    Xp, yp = make_positive_pairs(X_train, y_train)\n",
    "    Xn, yn = make_negative_pairs(X_train, y_train, n_pairs=len(yp))\n",
    "\n",
    "    X_pairs = np.vstack([Xp, Xn])\n",
    "    y_pairs = np.hstack([yp, yn])\n",
    "\n",
    "    siamese.fit(\n",
    "        [X_pairs[:, 0], X_pairs[:, 1]],\n",
    "        y_pairs,\n",
    "        batch_size=16,\n",
    "        epochs=10,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred = predict_patient_siamese(\n",
    "        siamese,\n",
    "        X_test[0],\n",
    "        X_train,\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    y_true_all.append(y_test[0])\n",
    "    y_pred_all.append(y_pred)\n",
    "\n",
    "report_siamese = classification_report(\n",
    "    y_true_all,\n",
    "    y_pred_all,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "report_siamese_df = pd.DataFrame(report_siamese).transpose()\n",
    "report_siamese_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3ca9dc1-8776-4a54-a933-8ce802c5597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_positive_pairs(X, y):\n",
    "    pairs, labels = [], []\n",
    "    for p in np.unique(y):\n",
    "        idx = np.where(y == p)[0]\n",
    "        for i in range(len(idx)):\n",
    "            for j in range(i + 1, len(idx)):\n",
    "                pairs.append([X[idx[i]], X[idx[j]]])\n",
    "                labels.append(1)\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f80dfa7-4d10-4011-a7b9-072668b2dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_negative_pairs_random(X, y, n_pairs):\n",
    "    pairs, labels = [], []\n",
    "    patients = np.unique(y)\n",
    "\n",
    "    for _ in range(n_pairs):\n",
    "        p1, p2 = np.random.choice(patients, 2, replace=False)\n",
    "        i = np.random.choice(np.where(y == p1)[0])\n",
    "        j = np.random.choice(np.where(y == p2)[0])\n",
    "        pairs.append([X[i], X[j]])\n",
    "        labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f26cc894-2edc-49e7-a3ea-ccfd30ba4951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_negative_pairs_hard(X, y, n_pairs, n_components=50):\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    D = euclidean_distances(X_pca, X_pca)\n",
    "    mask = y[:, None] != y[None, :]\n",
    "    D = np.where(mask, D, np.inf)\n",
    "\n",
    "    pairs, labels = [], []\n",
    "\n",
    "    flat_idx = np.argsort(D, axis=None)[:n_pairs]\n",
    "\n",
    "    for idx in flat_idx:\n",
    "        i, j = np.unravel_index(idx, D.shape)\n",
    "        pairs.append([X[i], X[j]])\n",
    "        labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83feef13-0cef-42bc-a13d-40a772839feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def build_siamese(input_dim):\n",
    "\n",
    "    inp = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(\n",
    "        256, activation=\"relu\",\n",
    "        kernel_regularizer=regularizers.l2(1e-4)\n",
    "    )(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = layers.Dense(\n",
    "        128, activation=\"relu\",\n",
    "        kernel_regularizer=regularizers.l2(1e-4)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    embedding = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(x)\n",
    "\n",
    "    base = Model(inp, embedding)\n",
    "\n",
    "    a = layers.Input(shape=(input_dim,))\n",
    "    b = layers.Input(shape=(input_dim,))\n",
    "\n",
    "    ea = base(a)\n",
    "    eb = base(b)\n",
    "\n",
    "    dist = layers.Lambda(\n",
    "        lambda x: tf.reduce_sum(tf.square(x[0] - x[1]), axis=1, keepdims=True)\n",
    "    )([ea, eb])\n",
    "\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(dist)\n",
    "\n",
    "    model = Model([a, b], out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\"\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "569ed572-d6ee-4811-be66-567e2129e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_patient_siamese(model, x_test, X_train, y_train):\n",
    "\n",
    "    scores = []\n",
    "    for x_tr, p in zip(X_train, y_train):\n",
    "        s = model.predict(\n",
    "            [x_test.reshape(1,-1), x_tr.reshape(1,-1)],\n",
    "            verbose=0\n",
    "        )[0][0]\n",
    "        scores.append((p, s))\n",
    "\n",
    "    df = pd.DataFrame(scores, columns=[\"patient\", \"score\"])\n",
    "    return df.groupby(\"patient\")[\"score\"].mean().idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "682f25ce-f640-4e1f-89e6-8ceb771b869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f43a4a1-881a-4751-931d-55ca4bac85d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.22         8\n",
      "           1       0.25      0.38      0.30         8\n",
      "           2       0.08      0.25      0.12         8\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.27      0.38      0.32         8\n",
      "           6       0.43      0.38      0.40         8\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.07      0.25      0.11         8\n",
      "          10       0.20      0.12      0.15         8\n",
      "          11       0.00      0.00      0.00         8\n",
      "          12       0.38      0.38      0.38         8\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.14      0.12      0.13         8\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.50      0.25      0.33         8\n",
      "          18       0.27      0.43      0.33         7\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.50      0.12      0.20         8\n",
      "          21       0.50      0.12      0.20         8\n",
      "          22       0.00      0.00      0.00         8\n",
      "          23       0.17      0.86      0.29         7\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         6\n",
      "          26       0.24      0.33      0.28        12\n",
      "\n",
      "    accuracy                           0.17       215\n",
      "   macro avg       0.19      0.17      0.14       215\n",
      "weighted avg       0.19      0.17      0.14       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "\n",
    "for train_idx, test_idx in reidentification_cv(df_all):\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    Xp, yp = make_positive_pairs(X_train, y_train)\n",
    "    Xn, yn = make_negative_pairs_random(X_train, y_train, len(yp))\n",
    "\n",
    "    X_pairs = np.vstack([Xp, Xn])\n",
    "    y_pairs = np.hstack([yp, yn])\n",
    "\n",
    "    model = build_siamese(X.shape[1])\n",
    "    model.fit(\n",
    "        [X_pairs[:,0], X_pairs[:,1]],\n",
    "        y_pairs,\n",
    "        epochs=3,\n",
    "        batch_size=16,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pred = predict_patient_siamese(model, X_test[0], X_train, y_train)\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8ee6df5-b35b-435d-8798-30b1ee12e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.11      0.12      0.12         8\n",
      "           2       0.03      0.12      0.05         8\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.16      0.50      0.24         8\n",
      "           6       0.30      0.38      0.33         8\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.19      0.38      0.25         8\n",
      "           9       0.10      0.12      0.11         8\n",
      "          10       0.33      0.12      0.18         8\n",
      "          11       0.13      0.38      0.19         8\n",
      "          12       0.50      0.12      0.20         8\n",
      "          13       0.33      0.12      0.18         8\n",
      "          14       0.28      0.62      0.38         8\n",
      "          15       0.33      0.12      0.18         8\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.18      0.29      0.22         7\n",
      "          19       0.20      0.12      0.15         8\n",
      "          20       0.50      0.12      0.20         8\n",
      "          21       0.00      0.00      0.00         8\n",
      "          22       0.25      0.25      0.25         8\n",
      "          23       0.18      0.29      0.22         7\n",
      "          24       0.50      0.12      0.20         8\n",
      "          25       0.33      0.33      0.33         6\n",
      "          26       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.19       215\n",
      "   macro avg       0.20      0.18      0.16       215\n",
      "weighted avg       0.20      0.19      0.16       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for train_idx, test_idx in reidentification_cv(df_all):\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    Xp, yp = make_positive_pairs(X_train, y_train)\n",
    "    Xn, yn = make_negative_pairs_hard(X_train, y_train, len(yp))\n",
    "\n",
    "    X_pairs = np.vstack([Xp, Xn])\n",
    "    y_pairs = np.hstack([yp, yn])\n",
    "\n",
    "    model = build_siamese(X.shape[1])\n",
    "    model.fit(\n",
    "        [X_pairs[:,0], X_pairs[:,1]],\n",
    "        y_pairs,\n",
    "        epochs=3,\n",
    "        batch_size=16,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pred = predict_patient_siamese(model, X_test[0], X_train, y_train)\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e62011d5-e8bb-421a-a27f-fe0444468ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noctrl = df_all[df_all[\"patient\"] != \"ZZ_control\"].copy()\n",
    "X_nc = np.vstack(df_noctrl[\"expression\"].values)\n",
    "y_nc = df_noctrl[\"patient\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63857c00-fa55-4c97-9bf9-272d696f8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "907e451c-8f6d-49c3-b02f-80dbee47bef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.12      0.13         8\n",
      "           1       0.20      0.12      0.15         8\n",
      "           2       0.04      0.12      0.06         8\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.36      0.50      0.42         8\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.08      0.12      0.10         8\n",
      "           9       0.00      0.00      0.00         8\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00         8\n",
      "          12       0.33      0.12      0.18         8\n",
      "          13       0.25      0.12      0.17         8\n",
      "          14       0.06      0.25      0.10         8\n",
      "          15       1.00      0.38      0.55         8\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00         7\n",
      "          19       0.10      0.12      0.11         8\n",
      "          20       0.25      0.12      0.17         8\n",
      "          21       0.00      0.00      0.00         8\n",
      "          22       0.67      0.50      0.57         8\n",
      "          23       0.20      0.57      0.30         7\n",
      "          24       0.20      0.12      0.15         8\n",
      "          25       0.00      0.00      0.00         6\n",
      "          26       0.09      0.17      0.11        12\n",
      "\n",
      "    accuracy                           0.13       215\n",
      "   macro avg       0.15      0.13      0.12       215\n",
      "weighted avg       0.15      0.13      0.12       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "\n",
    "for train_idx, test_idx in reidentification_cv(df_all):\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    Xp, yp = make_positive_pairs(X_train, y_train)\n",
    "    Xn, yn = make_negative_pairs_hard(X_train, y_train, len(yp))\n",
    "\n",
    "    X_pairs = np.vstack([Xp, Xn])\n",
    "    y_pairs = np.hstack([yp, yn])\n",
    "\n",
    "    model = build_siamese(X.shape[1])\n",
    "\n",
    "    model.fit(\n",
    "        [X_pairs[:,0], X_pairs[:,1]],\n",
    "        y_pairs,\n",
    "        epochs=15,\n",
    "        batch_size=32,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"loss\",\n",
    "                patience=3,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pred = predict_patient_siamese(\n",
    "        model, X_test[0], X_train, y_train\n",
    "    )\n",
    "\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd5af3b1-32e8-4b34-bffc-c4ffeafd2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp, yp = make_positive_pairs(X, y)\n",
    "Xn, yn = make_negative_pairs_hard(X, y, n_pairs=3*len(yp))\n",
    "\n",
    "X_pairs = np.vstack([Xp, Xn])\n",
    "y_pairs = np.hstack([yp, yn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19b91c91-fca5-40fa-b664-5d0fef6815d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 1.0654\n",
      "Epoch 2/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.8380\n",
      "Epoch 3/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - loss: 0.7604\n",
      "Epoch 4/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.7147\n",
      "Epoch 5/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.6799\n",
      "Epoch 6/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.6554\n",
      "Epoch 7/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.6340\n",
      "Epoch 8/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.6171\n",
      "Epoch 9/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.6006\n",
      "Epoch 10/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.5835\n",
      "Epoch 11/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.5715\n",
      "Epoch 12/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.5658\n",
      "Epoch 13/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.5519\n",
      "Epoch 14/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.5395\n",
      "Epoch 15/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 0.5372\n",
      "Epoch 16/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.5238\n",
      "Epoch 17/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.5188\n",
      "Epoch 18/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.5086\n",
      "Epoch 19/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.5002\n",
      "Epoch 20/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.4926\n",
      "Epoch 21/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.4865\n",
      "Epoch 22/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.4814\n",
      "Epoch 23/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.4703\n",
      "Epoch 24/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.4658\n",
      "Epoch 25/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.4636\n",
      "Epoch 26/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.4579\n",
      "Epoch 27/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.4509\n",
      "Epoch 28/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.4486\n",
      "Epoch 29/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.4407\n",
      "Epoch 30/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.4299\n",
      "Epoch 31/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.4277\n",
      "Epoch 32/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.4220\n",
      "Epoch 33/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.4218\n",
      "Epoch 34/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.4137\n",
      "Epoch 35/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.4048\n",
      "Epoch 36/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.4029\n",
      "Epoch 37/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.4039\n",
      "Epoch 38/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.3963\n",
      "Epoch 39/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.3931\n",
      "Epoch 40/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.3952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24df059f170>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_siamese(X.shape[1])\n",
    "\n",
    "model.fit(\n",
    "    [X_pairs[:,0], X_pairs[:,1]],\n",
    "    y_pairs,\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c345ba07-4a09-4a17-bcfe-595cb866a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = model.layers[2]  # base network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0067dcb-03b2-445c-a8b3-072dacbd1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_patient_embedding(x_test, X_train, y_train, embed):\n",
    "\n",
    "    z_test = embed.predict(x_test.reshape(1,-1), verbose=0)\n",
    "    Z_train = embed.predict(X_train, verbose=0)\n",
    "\n",
    "    dists = euclidean_distances(z_test, Z_train)[0]\n",
    "    df = pd.DataFrame({\n",
    "        \"patient\": y_train,\n",
    "        \"dist\": dists\n",
    "    })\n",
    "\n",
    "    return df.groupby(\"patient\")[\"dist\"].mean().idxmin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c3db9f0-9de7-4866-8c7f-2c1941e1bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       0.75      0.38      0.50         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       1.00      0.62      0.77         8\n",
      "           7       1.00      1.00      1.00         7\n",
      "           8       1.00      0.88      0.93         8\n",
      "           9       0.75      0.75      0.75         8\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         8\n",
      "          12       1.00      1.00      1.00         8\n",
      "          13       1.00      1.00      1.00         8\n",
      "          14       1.00      1.00      1.00         8\n",
      "          15       0.58      0.88      0.70         8\n",
      "          16       0.75      0.75      0.75         8\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         7\n",
      "          19       0.89      1.00      0.94         8\n",
      "          20       1.00      1.00      1.00         8\n",
      "          21       1.00      1.00      1.00         8\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       0.70      1.00      0.82         7\n",
      "          24       1.00      1.00      1.00         8\n",
      "          25       1.00      1.00      1.00         6\n",
      "          26       0.60      1.00      0.75        12\n",
      "\n",
      "    accuracy                           0.90       215\n",
      "   macro avg       0.89      0.90      0.89       215\n",
      "weighted avg       0.88      0.90      0.88       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "\n",
    "for train_idx, test_idx in reidentification_cv(df_all):\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    pred = predict_patient_embedding(\n",
    "        X_test[0], X_train, y_train, embedding_model\n",
    "    )\n",
    "\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86daa4cc-43ef-4f81-9d1f-d036e3f0b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cihan\\ki-al-miRNA-attack\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F691DA6480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F691F76340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.18      0.25      0.21         8\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.33      0.62      0.43         8\n",
      "           6       0.12      0.12      0.12         8\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.33      0.25      0.29         8\n",
      "           9       0.06      0.12      0.08         8\n",
      "          10       0.29      0.25      0.27         8\n",
      "          11       0.00      0.00      0.00         8\n",
      "          12       0.25      0.12      0.17         8\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.46      0.75      0.57         8\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.50      0.12      0.20         8\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.25      0.29      0.27         7\n",
      "          19       0.08      0.12      0.10         8\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.07      0.12      0.09         8\n",
      "          22       0.10      0.12      0.11         8\n",
      "          23       0.14      0.14      0.14         7\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         6\n",
      "          26       0.36      0.33      0.35        12\n",
      "\n",
      "    accuracy                           0.14       215\n",
      "   macro avg       0.13      0.14      0.13       215\n",
      "weighted avg       0.14      0.14      0.13       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "\n",
    "# --- reidentification CV (seninki) ---\n",
    "def reidentification_cv(df):\n",
    "    for patient, df_p in df.groupby(\"patient\"):\n",
    "        for test_idx in df_p.index:\n",
    "            train_idx = df.index.difference([test_idx])\n",
    "            yield train_idx.to_numpy(), np.array([test_idx])\n",
    "\n",
    "# --- pair makers (seninki) ---\n",
    "def make_positive_pairs(X, y):\n",
    "    pairs, labels = [], []\n",
    "    for p in np.unique(y):\n",
    "        idx = np.where(y == p)[0]\n",
    "        for i in range(len(idx)):\n",
    "            for j in range(i + 1, len(idx)):\n",
    "                pairs.append([X[idx[i]], X[idx[j]]])\n",
    "                labels.append(1)\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def make_negative_pairs_hard(X, y, n_pairs, n_components=50):\n",
    "    pca = PCA(n_components=min(n_components, X.shape[1]))\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    D = euclidean_distances(X_pca, X_pca)\n",
    "    mask = y[:, None] != y[None, :]\n",
    "    D = np.where(mask, D, np.inf)\n",
    "\n",
    "    flat_idx = np.argsort(D, axis=None)[:n_pairs]\n",
    "    pairs, labels = [], []\n",
    "    for idx in flat_idx:\n",
    "        i, j = np.unravel_index(idx, D.shape)\n",
    "        pairs.append([X[i], X[j]])\n",
    "        labels.append(0)\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "# --- siamese builder (seninki ama base'i ayrıca döndürüyorum) ---\n",
    "def build_siamese(input_dim):\n",
    "    inp = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(256, activation=\"relu\",\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"relu\",\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    embedding = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(x)\n",
    "\n",
    "    base = Model(inp, embedding, name=\"embedder\")\n",
    "\n",
    "    a = layers.Input(shape=(input_dim,))\n",
    "    b = layers.Input(shape=(input_dim,))\n",
    "    ea = base(a)\n",
    "    eb = base(b)\n",
    "\n",
    "    dist = layers.Lambda(lambda z: tf.reduce_sum(tf.square(z[0]-z[1]),\n",
    "                                                 axis=1, keepdims=True))([ea, eb])\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(dist)\n",
    "\n",
    "    model = Model([a, b], out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"binary_crossentropy\")\n",
    "    return model, base\n",
    "\n",
    "# --- embedding ile patient tahmini (mean distance) ---\n",
    "def predict_patient_embedding(embedder, x_test, X_train, y_train):\n",
    "    z_test = embedder.predict(x_test.reshape(1,-1), verbose=0)\n",
    "    Z_train = embedder.predict(X_train, verbose=0)\n",
    "    d = euclidean_distances(z_test, Z_train)[0]\n",
    "    df = pd.DataFrame({\"patient\": y_train, \"dist\": d})\n",
    "    return df.groupby(\"patient\")[\"dist\"].mean().idxmin()\n",
    "\n",
    "# =========================\n",
    "#   LEAKAGE-FREE EVAL\n",
    "# =========================\n",
    "\n",
    "# X ve y burada hazır olmalı:\n",
    "# X = np.vstack(df_all[\"expression\"].values)\n",
    "# y = df_all[\"patient\"].values  # string label önerilir\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(reidentification_cv(df_all), 1):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # pairs sadece TRAIN'den\n",
    "    Xp, yp = make_positive_pairs(X_train, y_train)\n",
    "    Xn, yn = make_negative_pairs_hard(X_train, y_train, n_pairs=len(yp))\n",
    "\n",
    "    X_pairs = np.vstack([Xp, Xn])\n",
    "    y_pairs = np.hstack([yp, yn])\n",
    "\n",
    "    # her fold'da yeni model (doğru ama maliyetli)\n",
    "    siamese, embedder = build_siamese(X_train.shape[1])\n",
    "\n",
    "    siamese.fit(\n",
    "        [X_pairs[:,0], X_pairs[:,1]],\n",
    "        y_pairs,\n",
    "        epochs=30,\n",
    "        batch_size=64,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"loss\", patience=5, restore_best_weights=True\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    pred = predict_patient_embedding(embedder, X_test[0], X_train, y_train)\n",
    "\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96978e84-d1b3-4076-aa5c-02ac3b4f80d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model eğitiliyor...\n",
      "Positive pairs: 760\n",
      "Negative pairs: 2280\n",
      "Epoch 1/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2531 - loss: 1.1522 - val_accuracy: 0.4430 - val_loss: 0.7180 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2531 - loss: 0.9790 - val_accuracy: 0.4539 - val_loss: 0.7189 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2535 - loss: 0.9238 - val_accuracy: 0.6140 - val_loss: 0.6929 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2531 - loss: 0.8740 - val_accuracy: 0.8355 - val_loss: 0.6678 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2554 - loss: 0.8336 - val_accuracy: 0.7039 - val_loss: 0.6819 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2659 - loss: 0.7939 - val_accuracy: 0.6711 - val_loss: 0.6775 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2806 - loss: 0.7625 - val_accuracy: 0.7390 - val_loss: 0.6526 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3375 - loss: 0.7336 - val_accuracy: 0.7346 - val_loss: 0.6406 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4334 - loss: 0.7146 - val_accuracy: 0.7807 - val_loss: 0.6263 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5267 - loss: 0.6876 - val_accuracy: 0.8136 - val_loss: 0.6032 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6324 - loss: 0.6668 - val_accuracy: 0.8377 - val_loss: 0.5954 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6966 - loss: 0.6529 - val_accuracy: 0.8487 - val_loss: 0.5871 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7485 - loss: 0.6377 - val_accuracy: 0.8816 - val_loss: 0.5704 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8011 - loss: 0.6235 - val_accuracy: 0.8421 - val_loss: 0.5707 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8270 - loss: 0.6103 - val_accuracy: 0.8706 - val_loss: 0.5514 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8479 - loss: 0.6008 - val_accuracy: 0.8838 - val_loss: 0.5426 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8607 - loss: 0.5928 - val_accuracy: 0.8904 - val_loss: 0.5353 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8769 - loss: 0.5814 - val_accuracy: 0.8794 - val_loss: 0.5297 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8800 - loss: 0.5724 - val_accuracy: 0.8860 - val_loss: 0.5206 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8827 - loss: 0.5673 - val_accuracy: 0.8794 - val_loss: 0.5192 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8812 - loss: 0.5597 - val_accuracy: 0.8706 - val_loss: 0.5128 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8812 - loss: 0.5531 - val_accuracy: 0.8794 - val_loss: 0.5081 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8816 - loss: 0.5458 - val_accuracy: 0.8728 - val_loss: 0.5027 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8796 - loss: 0.5408 - val_accuracy: 0.8684 - val_loss: 0.4964 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8723 - loss: 0.5397 - val_accuracy: 0.8728 - val_loss: 0.5058 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8773 - loss: 0.5304 - val_accuracy: 0.8684 - val_loss: 0.4899 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8723 - loss: 0.5279 - val_accuracy: 0.8596 - val_loss: 0.4926 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8789 - loss: 0.5199 - val_accuracy: 0.8706 - val_loss: 0.4810 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8676 - loss: 0.5177 - val_accuracy: 0.8684 - val_loss: 0.4718 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8688 - loss: 0.5137 - val_accuracy: 0.8553 - val_loss: 0.4807 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8684 - loss: 0.5090 - val_accuracy: 0.8706 - val_loss: 0.4656 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8746 - loss: 0.5025 - val_accuracy: 0.8662 - val_loss: 0.4608 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8704 - loss: 0.5002 - val_accuracy: 0.8662 - val_loss: 0.4604 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8719 - loss: 0.4943 - val_accuracy: 0.8640 - val_loss: 0.4576 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8700 - loss: 0.4922 - val_accuracy: 0.8640 - val_loss: 0.4499 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8680 - loss: 0.4890 - val_accuracy: 0.8618 - val_loss: 0.4501 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8727 - loss: 0.4827 - val_accuracy: 0.8531 - val_loss: 0.4549 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8657 - loss: 0.4816 - val_accuracy: 0.8662 - val_loss: 0.4657 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8707 - loss: 0.4800 - val_accuracy: 0.8575 - val_loss: 0.4438 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8707 - loss: 0.4744 - val_accuracy: 0.8553 - val_loss: 0.4446 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8696 - loss: 0.4715 - val_accuracy: 0.8531 - val_loss: 0.4371 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8750 - loss: 0.4656 - val_accuracy: 0.8553 - val_loss: 0.4355 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8704 - loss: 0.4649 - val_accuracy: 0.8553 - val_loss: 0.4374 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8704 - loss: 0.4629 - val_accuracy: 0.8443 - val_loss: 0.4425 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8700 - loss: 0.4589 - val_accuracy: 0.8618 - val_loss: 0.4253 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8723 - loss: 0.4510 - val_accuracy: 0.8618 - val_loss: 0.4240 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8738 - loss: 0.4494 - val_accuracy: 0.8596 - val_loss: 0.4209 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8727 - loss: 0.4469 - val_accuracy: 0.8553 - val_loss: 0.4240 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8723 - loss: 0.4448 - val_accuracy: 0.8596 - val_loss: 0.4164 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8731 - loss: 0.4389 - val_accuracy: 0.8465 - val_loss: 0.4899 - learning_rate: 0.0010\n",
      "\n",
      "Global model ile CV değerlendirmesi yapılıyor...\n",
      "\n",
      "Fold 50/215 tamamlandı...\n",
      "Fold 100/215 tamamlandı...\n",
      "Fold 150/215 tamamlandı...\n",
      "Fold 200/215 tamamlandı...\n",
      "\n",
      "==================================================\n",
      "GLOBAL MODEL SONUÇLARI\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.05      0.38      0.08         8\n",
      "           9       0.00      0.00      0.00         8\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00         8\n",
      "          12       0.00      0.00      0.00         8\n",
      "          13       0.00      0.00      0.00         8\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00         7\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.04      0.38      0.07         8\n",
      "          22       0.00      0.00      0.00         8\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         6\n",
      "          26       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.03       215\n",
      "   macro avg       0.00      0.03      0.01       215\n",
      "weighted avg       0.00      0.03      0.01       215\n",
      "\n",
      "\n",
      "==================================================\n",
      "EMBEDDING KALİTESİ\n",
      "==================================================\n",
      "Tüm veri Silhouette Score: -0.313\n",
      "(> 0.5 iyi, > 0.7 çok iyi)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "\n",
    "# ============================================\n",
    "#  1. CV ve Pair Fonksiyonları\n",
    "# ============================================\n",
    "\n",
    "def reidentification_cv(df):\n",
    "    \"\"\"Her hasta için her örneği bir kez test olarak bırak\"\"\"\n",
    "    for patient, df_p in df.groupby(\"patient\"):\n",
    "        for test_idx in df_p.index:\n",
    "            train_idx = df.index.difference([test_idx])\n",
    "            yield train_idx.to_numpy(), np.array([test_idx])\n",
    "\n",
    "def make_positive_pairs(X, y):\n",
    "    \"\"\"Aynı hastadan gelen tüm çiftleri oluştur\"\"\"\n",
    "    pairs, labels = [], []\n",
    "    for p in np.unique(y):\n",
    "        idx = np.where(y == p)[0]\n",
    "        for i in range(len(idx)):\n",
    "            for j in range(i + 1, len(idx)):\n",
    "                pairs.append([X[idx[i]], X[idx[j]]])\n",
    "                labels.append(1)\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def make_negative_pairs_hard(X, y, n_pairs, n_components=100):\n",
    "    \"\"\"En yakın (hard) negative çiftleri bul\"\"\"\n",
    "    # PCA ile boyut azalt\n",
    "    pca = PCA(n_components=min(n_components, X.shape[1]))\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # Mesafe matrisi hesapla\n",
    "    D = euclidean_distances(X_pca, X_pca)\n",
    "    \n",
    "    # Sadece farklı hastaları maskele\n",
    "    mask = y[:, None] != y[None, :]\n",
    "    D = np.where(mask, D, np.inf)\n",
    "    \n",
    "    # En yakın n_pairs çifti al\n",
    "    flat_idx = np.argsort(D, axis=None)[:n_pairs]\n",
    "    pairs, labels = [], []\n",
    "    for idx in flat_idx:\n",
    "        i, j = np.unravel_index(idx, D.shape)\n",
    "        pairs.append([X[i], X[j]])\n",
    "        labels.append(0)\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "# ============================================\n",
    "#  2. Basitleştirilmiş Siamese Model\n",
    "# ============================================\n",
    "\n",
    "def build_siamese_network(input_dim):\n",
    "    \"\"\"Daha basit ve sağlam bir Siamese ağı\"\"\"\n",
    "    # Embedding network (base)\n",
    "    inp = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(128, activation=\"relu\",\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation=\"relu\",\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # L2 normalize edilmiş embedding\n",
    "    embedding = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(x)\n",
    "    \n",
    "    base = Model(inp, embedding, name=\"embedder\")\n",
    "    \n",
    "    # Siamese yapısı\n",
    "    a = layers.Input(shape=(input_dim,))\n",
    "    b = layers.Input(shape=(input_dim,))\n",
    "    ea = base(a)\n",
    "    eb = base(b)\n",
    "    \n",
    "    # L2 distance\n",
    "    dist = layers.Lambda(lambda z: tf.reduce_sum(tf.square(z[0] - z[1]),\n",
    "                                                  axis=1, keepdims=True))([ea, eb])\n",
    "    \n",
    "    # Sigmoid ile [0,1] aralığına çevir\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(dist)\n",
    "    \n",
    "    model = Model([a, b], out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model, base\n",
    "\n",
    "# ============================================\n",
    "#  3. Tahmin Fonksiyonu\n",
    "# ============================================\n",
    "\n",
    "def predict_patient_embedding(embedder, x_test, X_train, y_train):\n",
    "    \"\"\"Test örneğinin en yakın hastasını bul\"\"\"\n",
    "    z_test = embedder.predict(x_test.reshape(1, -1), verbose=0)\n",
    "    Z_train = embedder.predict(X_train, verbose=0)\n",
    "    \n",
    "    # Her train örneğine mesafe\n",
    "    d = euclidean_distances(z_test, Z_train)[0]\n",
    "    \n",
    "    # Hasta bazında ortalama mesafe\n",
    "    df = pd.DataFrame({\"patient\": y_train, \"dist\": d})\n",
    "    return df.groupby(\"patient\")[\"dist\"].mean().idxmin()\n",
    "\n",
    "# ============================================\n",
    "#  4. GLOBAL MODEL YAKLAŞIMI (ÖNERİLEN)\n",
    "# ============================================\n",
    "\n",
    "def train_global_model(X, y):\n",
    "    \"\"\"Tüm veriyle tek bir model eğit\"\"\"\n",
    "    print(\"Global model eğitiliyor...\")\n",
    "    \n",
    "    # Tüm positive pairs\n",
    "    Xp, yp = make_positive_pairs(X, y)\n",
    "    print(f\"Positive pairs: {len(yp)}\")\n",
    "    \n",
    "    # 3x daha fazla negative pair\n",
    "    Xn, yn = make_negative_pairs_hard(X, y, n_pairs=len(yp) * 3, n_components=100)\n",
    "    print(f\"Negative pairs: {len(yn)}\")\n",
    "    \n",
    "    # Birleştir\n",
    "    X_pairs = np.vstack([Xp, Xn])\n",
    "    y_pairs = np.hstack([yp, yn])\n",
    "    \n",
    "    # Karıştır\n",
    "    idx = np.random.permutation(len(y_pairs))\n",
    "    X_pairs = X_pairs[idx]\n",
    "    y_pairs = y_pairs[idx]\n",
    "    \n",
    "    # Model\n",
    "    siamese, embedder = build_siamese_network(X.shape[1])\n",
    "    \n",
    "    # Eğit\n",
    "    history = siamese.fit(\n",
    "        [X_pairs[:, 0], X_pairs[:, 1]],\n",
    "        y_pairs,\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        validation_split=0.15,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\",\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return siamese, embedder, history\n",
    "\n",
    "def evaluate_global_model(embedder, df_all, X, y):\n",
    "    \"\"\"Global model ile CV değerlendirmesi\"\"\"\n",
    "    print(\"\\nGlobal model ile CV değerlendirmesi yapılıyor...\\n\")\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(reidentification_cv(df_all), 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Tahmin\n",
    "        pred = predict_patient_embedding(embedder, X_test[0], X_train, y_train)\n",
    "        \n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(pred)\n",
    "        \n",
    "        if fold % 50 == 0:\n",
    "            print(f\"Fold {fold}/215 tamamlandı...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"GLOBAL MODEL SONUÇLARI\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "# ============================================\n",
    "#  5. PER-FOLD MODEL YAKLAŞIMI (ALTERNATIF)\n",
    "# ============================================\n",
    "\n",
    "def evaluate_per_fold_model(df_all, X, y):\n",
    "    \"\"\"Her fold için ayrı model eğit (yavaş ama leakage-free)\"\"\"\n",
    "    print(\"\\nHer fold için ayrı model eğitiliyor...\\n\")\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(reidentification_cv(df_all), 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train pairs\n",
    "        Xp, yp = make_positive_pairs(X_train, y_train)\n",
    "        Xn, yn = make_negative_pairs_hard(X_train, y_train, \n",
    "                                          n_pairs=len(yp) * 2, \n",
    "                                          n_components=100)\n",
    "        \n",
    "        X_pairs = np.vstack([Xp, Xn])\n",
    "        y_pairs = np.hstack([yp, yn])\n",
    "        \n",
    "        # Yeni model\n",
    "        siamese, embedder = build_siamese_network(X_train.shape[1])\n",
    "        \n",
    "        # Eğit (az epoch, çabuk bitsin)\n",
    "        siamese.fit(\n",
    "            [X_pairs[:, 0], X_pairs[:, 1]],\n",
    "            y_pairs,\n",
    "            epochs=30,\n",
    "            batch_size=64,\n",
    "            verbose=0,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"loss\",\n",
    "                    patience=5,\n",
    "                    restore_best_weights=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Embedding kalitesi\n",
    "        Z_train = embedder.predict(X_train, verbose=0)\n",
    "        sil_score = silhouette_score(Z_train, y_train)\n",
    "        silhouette_scores.append(sil_score)\n",
    "        \n",
    "        # Tahmin\n",
    "        pred = predict_patient_embedding(embedder, X_test[0], X_train, y_train)\n",
    "        \n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(pred)\n",
    "        \n",
    "        if fold % 50 == 0:\n",
    "            print(f\"Fold {fold}/215 - Silhouette: {sil_score:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PER-FOLD MODEL SONUÇLARI\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Ortalama Silhouette Score: {np.mean(silhouette_scores):.3f}\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "# ============================================\n",
    "#  6. ANA ÇALIŞTIRMA\n",
    "# ============================================\n",
    "\n",
    "# Veriyi hazırla (df_all, X, y zaten mevcut olmalı)\n",
    "# X = np.vstack(df_all[\"expression\"].values)\n",
    "# y = df_all[\"patient\"].values\n",
    "\n",
    "# YÖNTEM 1: GLOBAL MODEL (ÖNERİLEN - HIZLI)\n",
    "siamese_global, embedder_global, history = train_global_model(X, y)\n",
    "evaluate_global_model(embedder_global, df_all, X, y)\n",
    "\n",
    "# YÖNTEM 2: PER-FOLD MODEL (İSTEĞE BAĞLI - YAVAŞ)\n",
    "# evaluate_per_fold_model(df_all, X, y)\n",
    "\n",
    "# Embedding kalitesini kontrol et\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EMBEDDING KALİTESİ\")\n",
    "print(\"=\"*50)\n",
    "Z_all = embedder_global.predict(X, verbose=0)\n",
    "sil_all = silhouette_score(Z_all, y)\n",
    "print(f\"Tüm veri Silhouette Score: {sil_all:.3f}\")\n",
    "print(f\"(> 0.5 iyi, > 0.7 çok iyi)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a68e1bbe-cfb9-41b5-acc3-3dbac2a256e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " YÖNTEM 1: PURE SIAMESE (Leakage var - referans için)\n",
      "======================================================================\n",
      "ADIM 1: Global model eğitimi (tüm veriyle)\n",
      "============================================================\n",
      "GLOBAL SIAMESE MODEL EĞİTİLİYOR (TÜM VERİ)\n",
      "============================================================\n",
      "✓ Positive pairs: 760\n",
      "✓ Negative pairs: 3800\n",
      "Epoch 1/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.2682 - mae: 0.9400 - val_loss: 0.5555 - val_mae: 0.3267 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2086 - mae: 0.9386 - val_loss: 0.4154 - val_mae: 0.4396 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.1749 - mae: 0.9596 - val_loss: 0.2535 - val_mae: 0.6137 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1471 - mae: 0.9823 - val_loss: 0.1389 - val_mae: 0.9549 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1301 - mae: 1.0030 - val_loss: 0.1188 - val_mae: 0.9962 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1184 - mae: 1.0182 - val_loss: 0.1296 - val_mae: 0.9174 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1050 - mae: 1.0337 - val_loss: 0.0961 - val_mae: 1.0381 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0965 - mae: 1.0469 - val_loss: 0.0899 - val_mae: 1.0362 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0895 - mae: 1.0533 - val_loss: 0.0892 - val_mae: 1.0200 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0831 - mae: 1.0675 - val_loss: 0.0894 - val_mae: 0.9730 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0783 - mae: 1.0742 - val_loss: 0.0793 - val_mae: 1.0141 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0741 - mae: 1.0788 - val_loss: 0.0816 - val_mae: 1.0132 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0705 - mae: 1.0857 - val_loss: 0.0641 - val_mae: 1.0768 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0657 - mae: 1.0893 - val_loss: 0.0569 - val_mae: 1.1020 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0605 - mae: 1.1002 - val_loss: 0.0656 - val_mae: 1.0469 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0582 - mae: 1.1030 - val_loss: 0.0573 - val_mae: 1.0934 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0549 - mae: 1.1068 - val_loss: 0.0651 - val_mae: 1.0330 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0543 - mae: 1.1052 - val_loss: 0.0443 - val_mae: 1.1190 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0491 - mae: 1.1138 - val_loss: 0.0454 - val_mae: 1.1150 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0474 - mae: 1.1181 - val_loss: 0.0448 - val_mae: 1.0961 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0466 - mae: 1.1178 - val_loss: 0.0547 - val_mae: 1.0502 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0436 - mae: 1.1241 - val_loss: 0.0364 - val_mae: 1.1340 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0423 - mae: 1.1243 - val_loss: 0.1859 - val_mae: 0.6755 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0397 - mae: 1.1293 - val_loss: 0.0428 - val_mae: 1.0682 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0388 - mae: 1.1305 - val_loss: 0.0388 - val_mae: 1.1066 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0349 - mae: 1.1383 - val_loss: 0.0303 - val_mae: 1.1404 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0340 - mae: 1.1409 - val_loss: 0.0311 - val_mae: 1.1288 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0355 - mae: 1.1347 - val_loss: 0.1428 - val_mae: 0.7446 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0341 - mae: 1.1381 - val_loss: 0.0704 - val_mae: 0.9657 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0310 - mae: 1.1436 - val_loss: 0.0295 - val_mae: 1.1299 - learning_rate: 0.0010\n",
      "Epoch 31/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0309 - mae: 1.1451 - val_loss: 0.0425 - val_mae: 1.0554 - learning_rate: 0.0010\n",
      "Epoch 32/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0314 - mae: 1.1419 - val_loss: 0.0455 - val_mae: 1.0858 - learning_rate: 0.0010\n",
      "Epoch 33/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0308 - mae: 1.1451 - val_loss: 0.0525 - val_mae: 1.0116 - learning_rate: 0.0010\n",
      "Epoch 34/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0331 - mae: 1.1392 - val_loss: 0.1471 - val_mae: 0.7434 - learning_rate: 0.0010\n",
      "Epoch 35/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0326 - mae: 1.1368\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0301 - mae: 1.1461 - val_loss: 0.0296 - val_mae: 1.1324 - learning_rate: 0.0010\n",
      "Epoch 36/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0267 - mae: 1.1540 - val_loss: 0.0215 - val_mae: 1.1684 - learning_rate: 5.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0245 - mae: 1.1596 - val_loss: 0.0208 - val_mae: 1.1682 - learning_rate: 5.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0235 - mae: 1.1616 - val_loss: 0.0182 - val_mae: 1.1759 - learning_rate: 5.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0219 - mae: 1.1654 - val_loss: 0.0178 - val_mae: 1.1773 - learning_rate: 5.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0211 - mae: 1.1645 - val_loss: 0.0172 - val_mae: 1.1758 - learning_rate: 5.0000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0204 - mae: 1.1657 - val_loss: 0.0162 - val_mae: 1.1788 - learning_rate: 5.0000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0194 - mae: 1.1668 - val_loss: 0.0179 - val_mae: 1.1574 - learning_rate: 5.0000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0190 - mae: 1.1666 - val_loss: 0.0148 - val_mae: 1.1778 - learning_rate: 5.0000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183 - mae: 1.1676 - val_loss: 0.0144 - val_mae: 1.1779 - learning_rate: 5.0000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0177 - mae: 1.1679 - val_loss: 0.0137 - val_mae: 1.1787 - learning_rate: 5.0000e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0176 - mae: 1.1670 - val_loss: 0.0151 - val_mae: 1.1707 - learning_rate: 5.0000e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0172 - mae: 1.1686 - val_loss: 0.0137 - val_mae: 1.1700 - learning_rate: 5.0000e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0171 - mae: 1.1679 - val_loss: 0.0207 - val_mae: 1.1342 - learning_rate: 5.0000e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0276 - mae: 1.1428 - val_loss: 0.1071 - val_mae: 0.8229 - learning_rate: 5.0000e-04\n",
      "Epoch 50/60\n",
      "\u001b[1m57/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0261 - mae: 1.1502\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0238 - mae: 1.1520 - val_loss: 0.1622 - val_mae: 0.6926 - learning_rate: 5.0000e-04\n",
      "Epoch 51/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0184 - mae: 1.1640 - val_loss: 0.0141 - val_mae: 1.1746 - learning_rate: 2.5000e-04\n",
      "Epoch 52/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0170 - mae: 1.1680 - val_loss: 0.0131 - val_mae: 1.1806 - learning_rate: 2.5000e-04\n",
      "Epoch 53/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0166 - mae: 1.1694 - val_loss: 0.0127 - val_mae: 1.1819 - learning_rate: 2.5000e-04\n",
      "Epoch 54/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0160 - mae: 1.1707 - val_loss: 0.0123 - val_mae: 1.1825 - learning_rate: 2.5000e-04\n",
      "Epoch 55/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0157 - mae: 1.1706 - val_loss: 0.0120 - val_mae: 1.1837 - learning_rate: 2.5000e-04\n",
      "Epoch 56/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0151 - mae: 1.1726 - val_loss: 0.0117 - val_mae: 1.1831 - learning_rate: 2.5000e-04\n",
      "Epoch 57/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0147 - mae: 1.1729 - val_loss: 0.0113 - val_mae: 1.1849 - learning_rate: 2.5000e-04\n",
      "Epoch 58/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0143 - mae: 1.1729 - val_loss: 0.0111 - val_mae: 1.1851 - learning_rate: 2.5000e-04\n",
      "Epoch 59/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0139 - mae: 1.1741 - val_loss: 0.0108 - val_mae: 1.1838 - learning_rate: 2.5000e-04\n",
      "Epoch 60/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0135 - mae: 1.1749 - val_loss: 0.0103 - val_mae: 1.1851 - learning_rate: 2.5000e-04\n",
      "\n",
      "ADIM 2: Embedding kalitesini kontrol et\n",
      "\n",
      "============================================================\n",
      "EMBEDDING KALİTE ANALİZİ\n",
      "============================================================\n",
      "Silhouette Score: 0.717\n",
      "  → < 0: Kötü ayrışma\n",
      "  → 0-0.3: Zayıf ayrışma\n",
      "  → 0.3-0.5: Orta ayrışma\n",
      "  → 0.5-0.7: İyi ayrışma\n",
      "  → > 0.7: Çok iyi ayrışma\n",
      "\n",
      "Mesafe Analizi:\n",
      "  Hasta içi mesafe: 0.040 (aynı hasta örnekleri)\n",
      "  Hasta arası mesafe: 1.188 (farklı hasta örnekleri)\n",
      "  Oran (inter/intra): 29.372\n",
      "  → Oran > 1.5 ise model iyi ayırt ediyor\n",
      "\n",
      "ADIM 3: Cross-validation ile değerlendir\n",
      "\n",
      "============================================================\n",
      "GLOBAL MODEL DEĞERLENDİRMESİ (PDF Cell 52 mantığı)\n",
      "============================================================\n",
      "\n",
      "Fold 50/215 tamamlandı...\n",
      "Fold 100/215 tamamlandı...\n",
      "Fold 150/215 tamamlandı...\n",
      "Fold 200/215 tamamlandı...\n",
      "\n",
      "============================================================\n",
      "SONUÇLAR\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      0.75      0.86         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       0.89      1.00      0.94         8\n",
      "           6       1.00      0.25      0.40         8\n",
      "           7       1.00      1.00      1.00         7\n",
      "           8       0.58      0.88      0.70         8\n",
      "           9       1.00      1.00      1.00         8\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         8\n",
      "          12       1.00      1.00      1.00         8\n",
      "          13       1.00      1.00      1.00         8\n",
      "          14       1.00      1.00      1.00         8\n",
      "          15       0.80      1.00      0.89         8\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         7\n",
      "          19       0.88      0.88      0.88         8\n",
      "          20       1.00      1.00      1.00         8\n",
      "          21       1.00      1.00      1.00         8\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       0.78      1.00      0.88         7\n",
      "          24       1.00      1.00      1.00         8\n",
      "          25       1.00      1.00      1.00         6\n",
      "          26       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.95       215\n",
      "   macro avg       0.96      0.95      0.94       215\n",
      "weighted avg       0.96      0.95      0.94       215\n",
      "\n",
      "\n",
      "======================================================================\n",
      " YÖNTEM 2: HYBRID APPROACH (Leakage yok - asıl sonuç)\n",
      "======================================================================\n",
      "============================================================\n",
      "HYBRID APPROACH: Global Embedding + LogReg CV\n",
      "============================================================\n",
      "\n",
      "[1/3] Global Siamese embedding eğitiliyor...\n",
      "============================================================\n",
      "GLOBAL SIAMESE MODEL EĞİTİLİYOR (TÜM VERİ)\n",
      "============================================================\n",
      "✓ Positive pairs: 760\n",
      "✓ Negative pairs: 3800\n",
      "Epoch 1/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2756 - mae: 0.9255 - val_loss: 0.4983 - val_mae: 0.3630 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2121 - mae: 0.9316 - val_loss: 0.3990 - val_mae: 0.4489 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1764 - mae: 0.9438 - val_loss: 0.2708 - val_mae: 0.6059 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1484 - mae: 0.9698 - val_loss: 0.1574 - val_mae: 0.8922 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1312 - mae: 0.9933 - val_loss: 0.1170 - val_mae: 0.9674 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1189 - mae: 1.0134 - val_loss: 0.1023 - val_mae: 1.0143 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1080 - mae: 1.0257 - val_loss: 0.1136 - val_mae: 0.9871 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1022 - mae: 1.0301 - val_loss: 0.0869 - val_mae: 1.0544 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0925 - mae: 1.0483 - val_loss: 0.0885 - val_mae: 1.0359 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0861 - mae: 1.0566 - val_loss: 0.1029 - val_mae: 0.9693 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0814 - mae: 1.0650 - val_loss: 0.0726 - val_mae: 1.0663 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0764 - mae: 1.0736 - val_loss: 0.0689 - val_mae: 1.0608 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0723 - mae: 1.0786 - val_loss: 0.0919 - val_mae: 0.9849 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0673 - mae: 1.0890 - val_loss: 0.0580 - val_mae: 1.0953 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0631 - mae: 1.0949 - val_loss: 0.0685 - val_mae: 1.0545 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0606 - mae: 1.0999 - val_loss: 0.0541 - val_mae: 1.0862 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0591 - mae: 1.1031 - val_loss: 0.1236 - val_mae: 0.8553 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0553 - mae: 1.1081 - val_loss: 0.0886 - val_mae: 0.9556 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0516 - mae: 1.1136 - val_loss: 0.0436 - val_mae: 1.1236 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0514 - mae: 1.1116 - val_loss: 0.0494 - val_mae: 1.0792 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0472 - mae: 1.1156 - val_loss: 0.0405 - val_mae: 1.1270 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0455 - mae: 1.1198 - val_loss: 0.0366 - val_mae: 1.1304 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0435 - mae: 1.1261 - val_loss: 0.1041 - val_mae: 0.8507 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0424 - mae: 1.1257 - val_loss: 0.0859 - val_mae: 0.9087 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0406 - mae: 1.1304 - val_loss: 0.0546 - val_mae: 1.0515 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0383 - mae: 1.1371 - val_loss: 0.0474 - val_mae: 1.0712 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0364 - mae: 1.1369 - val_loss: 0.0297 - val_mae: 1.1543 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0332 - mae: 1.1438 - val_loss: 0.0651 - val_mae: 0.9539 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0323 - mae: 1.1457 - val_loss: 0.0454 - val_mae: 1.0145 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0322 - mae: 1.1454 - val_loss: 0.0344 - val_mae: 1.1039 - learning_rate: 0.0010\n",
      "Epoch 31/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0315 - mae: 1.1470 - val_loss: 0.0477 - val_mae: 1.0167 - learning_rate: 0.0010\n",
      "Epoch 32/60\n",
      "\u001b[1m58/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0317 - mae: 1.1513\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0331 - mae: 1.1430 - val_loss: 0.0575 - val_mae: 0.9980 - learning_rate: 0.0010\n",
      "Epoch 33/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0283 - mae: 1.1518 - val_loss: 0.0238 - val_mae: 1.1719 - learning_rate: 5.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0254 - mae: 1.1592 - val_loss: 0.0208 - val_mae: 1.1818 - learning_rate: 5.0000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0249 - mae: 1.1598 - val_loss: 0.0193 - val_mae: 1.1873 - learning_rate: 5.0000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0234 - mae: 1.1620 - val_loss: 0.0197 - val_mae: 1.1804 - learning_rate: 5.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0226 - mae: 1.1637 - val_loss: 0.0182 - val_mae: 1.1863 - learning_rate: 5.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0219 - mae: 1.1654 - val_loss: 0.0165 - val_mae: 1.1859 - learning_rate: 5.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0217 - mae: 1.1618 - val_loss: 0.0197 - val_mae: 1.1701 - learning_rate: 5.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0202 - mae: 1.1647 - val_loss: 0.0158 - val_mae: 1.1826 - learning_rate: 5.0000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0205 - mae: 1.1643 - val_loss: 0.0231 - val_mae: 1.1291 - learning_rate: 5.0000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0200 - mae: 1.1640 - val_loss: 0.0146 - val_mae: 1.1844 - learning_rate: 5.0000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0197 - mae: 1.1658 - val_loss: 0.0150 - val_mae: 1.1811 - learning_rate: 5.0000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0191 - mae: 1.1668 - val_loss: 0.0145 - val_mae: 1.1783 - learning_rate: 5.0000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0183 - mae: 1.1677 - val_loss: 0.0186 - val_mae: 1.1622 - learning_rate: 5.0000e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0179 - mae: 1.1671 - val_loss: 0.0153 - val_mae: 1.1670 - learning_rate: 5.0000e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m60/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0181 - mae: 1.1647\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0180 - mae: 1.1683 - val_loss: 0.0163 - val_mae: 1.1516 - learning_rate: 5.0000e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0167 - mae: 1.1699 - val_loss: 0.0119 - val_mae: 1.1903 - learning_rate: 2.5000e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0153 - mae: 1.1737 - val_loss: 0.0116 - val_mae: 1.1942 - learning_rate: 2.5000e-04\n",
      "Epoch 50/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0150 - mae: 1.1745 - val_loss: 0.0112 - val_mae: 1.1914 - learning_rate: 2.5000e-04\n",
      "Epoch 51/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0145 - mae: 1.1758 - val_loss: 0.0104 - val_mae: 1.1969 - learning_rate: 2.5000e-04\n",
      "Epoch 52/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0139 - mae: 1.1763 - val_loss: 0.0104 - val_mae: 1.1945 - learning_rate: 2.5000e-04\n",
      "Epoch 53/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0136 - mae: 1.1776 - val_loss: 0.0103 - val_mae: 1.1957 - learning_rate: 2.5000e-04\n",
      "Epoch 54/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0133 - mae: 1.1785 - val_loss: 0.0099 - val_mae: 1.1947 - learning_rate: 2.5000e-04\n",
      "Epoch 55/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0130 - mae: 1.1787 - val_loss: 0.0096 - val_mae: 1.1963 - learning_rate: 2.5000e-04\n",
      "Epoch 56/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0128 - mae: 1.1785 - val_loss: 0.0092 - val_mae: 1.1964 - learning_rate: 2.5000e-04\n",
      "Epoch 57/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0128 - mae: 1.1777 - val_loss: 0.0096 - val_mae: 1.1966 - learning_rate: 2.5000e-04\n",
      "Epoch 58/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0126 - mae: 1.1769 - val_loss: 0.0107 - val_mae: 1.1871 - learning_rate: 2.5000e-04\n",
      "Epoch 59/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0130 - mae: 1.1780 - val_loss: 0.0090 - val_mae: 1.1969 - learning_rate: 2.5000e-04\n",
      "Epoch 60/60\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0124 - mae: 1.1786 - val_loss: 0.0088 - val_mae: 1.1978 - learning_rate: 2.5000e-04\n",
      "\n",
      "[2/3] Tüm veri embedding space'e dönüştürülüyor...\n",
      "✓ Original shape: (215, 1205)\n",
      "✓ Embedding shape: (215, 64)\n",
      "\n",
      "[3/3] Embedding üzerinde CV yapılıyor...\n",
      "  Fold 50/215 tamamlandı...\n",
      "  Fold 100/215 tamamlandı...\n",
      "  Fold 150/215 tamamlandı...\n",
      "  Fold 200/215 tamamlandı...\n",
      "\n",
      "============================================================\n",
      "HYBRID APPROACH SONUÇLARI\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      0.88      0.93         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       0.75      0.75      0.75         8\n",
      "           7       1.00      1.00      1.00         7\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       1.00      1.00      1.00         8\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         8\n",
      "          12       1.00      1.00      1.00         8\n",
      "          13       1.00      1.00      1.00         8\n",
      "          14       1.00      1.00      1.00         8\n",
      "          15       0.89      1.00      0.94         8\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         7\n",
      "          19       0.31      0.50      0.38         8\n",
      "          20       1.00      1.00      1.00         8\n",
      "          21       1.00      1.00      1.00         8\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.53      1.00      0.70         8\n",
      "          25       1.00      1.00      1.00         6\n",
      "          26       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.90       215\n",
      "   macro avg       0.87      0.89      0.88       215\n",
      "weighted avg       0.87      0.90      0.88       215\n",
      "\n",
      "\n",
      "======================================================================\n",
      " SONUÇLARIN KARŞILAŞTIRILMASI\n",
      "======================================================================\n",
      "\n",
      "\n",
      "                 Method  Accuracy  F1-Score (macro) Leakage\n",
      "     LogReg + PCA (PDF)  0.488000          0.508000      No\n",
      "        SVM + PCA (PDF)  0.409000          0.401000      No\n",
      " Pure Siamese (leakage)  0.948837          0.944212     Yes\n",
      "Hybrid Siamese + LogReg  0.897674          0.877819      No\n",
      "\n",
      "======================================================================\n",
      " YORUMLAR\n",
      "======================================================================\n",
      "1. Pure Siamese yüksek accuracy gösteriyor ama LEAKAGE var\n",
      "2. Hybrid approach leakage-free ve LogReg'ten daha iyi olmalı\n",
      "3. Eğer Hybrid < LogReg ise, embedding kalitesi yetersiz demektir\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "\n",
    "# ============================================\n",
    "#  FONKSIYONLAR\n",
    "# ============================================\n",
    "\n",
    "def reidentification_cv(df):\n",
    "    \"\"\"Her hasta için her örneği bir kez test olarak bırak\"\"\"\n",
    "    for patient, df_p in df.groupby(\"patient\"):\n",
    "        for test_idx in df_p.index:\n",
    "            train_idx = df.index.difference([test_idx])\n",
    "            yield train_idx.to_numpy(), np.array([test_idx])\n",
    "\n",
    "def make_positive_pairs(X, y):\n",
    "    \"\"\"Aynı hastadan gelen tüm çiftleri oluştur\"\"\"\n",
    "    pairs, labels = [], []\n",
    "    for p in np.unique(y):\n",
    "        idx = np.where(y == p)[0]\n",
    "        for i in range(len(idx)):\n",
    "            for j in range(i + 1, len(idx)):\n",
    "                pairs.append([X[idx[i]], X[idx[j]]])\n",
    "                labels.append(1)\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def make_negative_pairs_hard(X, y, n_pairs, n_components=150):\n",
    "    \"\"\"En yakın (hard) negative çiftleri bul\"\"\"\n",
    "    pca = PCA(n_components=min(n_components, X.shape[1]))\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    D = euclidean_distances(X_pca, X_pca)\n",
    "    mask = y[:, None] != y[None, :]\n",
    "    D = np.where(mask, D, np.inf)\n",
    "    \n",
    "    flat_idx = np.argsort(D, axis=None)[:n_pairs]\n",
    "    pairs, labels = [], []\n",
    "    for idx in flat_idx:\n",
    "        i, j = np.unravel_index(idx, D.shape)\n",
    "        pairs.append([X[i], X[j]])\n",
    "        labels.append(0)\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "# ============================================\n",
    "#  MODEL - CONTRASTIVE LOSS\n",
    "# ============================================\n",
    "\n",
    "def build_siamese_contrastive(input_dim):\n",
    "    \"\"\"Contrastive loss kullanan Siamese network - GÜÇLÜ VERSİYON\"\"\"\n",
    "    # Base embedding network\n",
    "    inp = layers.Input(shape=(input_dim,))\n",
    "    \n",
    "    # Daha derin ve geniş\n",
    "    x = layers.Dense(512, activation=\"relu\", \n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(256, activation=\"relu\",\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    embedding = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(x)\n",
    "    \n",
    "    base = Model(inp, embedding, name=\"embedder\")\n",
    "    \n",
    "    # Siamese structure\n",
    "    a = layers.Input(shape=(input_dim,))\n",
    "    b = layers.Input(shape=(input_dim,))\n",
    "    ea = base(a)\n",
    "    eb = base(b)\n",
    "    \n",
    "    # Euclidean distance\n",
    "    dist = layers.Lambda(\n",
    "        lambda z: tf.sqrt(tf.reduce_sum(tf.square(z[0] - z[1]), axis=1, keepdims=True) + 1e-6)\n",
    "    )([ea, eb])\n",
    "    \n",
    "    model = Model([a, b], dist)\n",
    "    \n",
    "    # Contrastive loss\n",
    "    def contrastive_loss(y_true, y_pred, margin=1.0):\n",
    "        \"\"\"y_true: 1=similar, 0=dissimilar\"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss=contrastive_loss,\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model, base\n",
    "\n",
    "# ============================================\n",
    "#  GLOBAL MODEL EĞİTİMİ (PDF Cell 48 mantığı)\n",
    "# ============================================\n",
    "\n",
    "def train_global_siamese(X, y):\n",
    "    \"\"\"TÜM VERİYLE tek model eğit - PDF Cell 48-52 gibi\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"GLOBAL SIAMESE MODEL EĞİTİLİYOR (TÜM VERİ)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # TÜM positive pairs\n",
    "    Xp, yp = make_positive_pairs(X, y)\n",
    "    print(f\"✓ Positive pairs: {len(yp)}\")\n",
    "    \n",
    "    # 5x negative pairs (daha fazla!)\n",
    "    Xn, yn = make_negative_pairs_hard(X, y, n_pairs=len(yp) * 5, n_components=200)\n",
    "    print(f\"✓ Negative pairs: {len(yn)}\")\n",
    "    \n",
    "    # Birleştir ve karıştır\n",
    "    X_pairs = np.vstack([Xp, Xn])\n",
    "    y_pairs = np.hstack([yp, yn])\n",
    "    \n",
    "    idx = np.random.permutation(len(y_pairs))\n",
    "    X_pairs = X_pairs[idx]\n",
    "    y_pairs = y_pairs[idx]\n",
    "    \n",
    "    # Model oluştur\n",
    "    siamese, embedder = build_siamese_contrastive(X.shape[1])\n",
    "    \n",
    "    # Eğit (UZUN EĞİTİM - PDF'te 40 epoch)\n",
    "    history = siamese.fit(\n",
    "        [X_pairs[:, 0], X_pairs[:, 1]],\n",
    "        y_pairs,\n",
    "        epochs=60,\n",
    "        batch_size=64,\n",
    "        validation_split=0.15,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\",\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return siamese, embedder, history\n",
    "\n",
    "# ============================================\n",
    "#  TAHMİN FONKSİYONU\n",
    "# ============================================\n",
    "\n",
    "def predict_patient_embedding(embedder, x_test, X_train, y_train):\n",
    "    \"\"\"Test örneğinin en yakın hastasını bul\"\"\"\n",
    "    z_test = embedder.predict(x_test.reshape(1, -1), verbose=0)\n",
    "    Z_train = embedder.predict(X_train, verbose=0)\n",
    "    \n",
    "    d = euclidean_distances(z_test, Z_train)[0]\n",
    "    df = pd.DataFrame({\"patient\": y_train, \"dist\": d})\n",
    "    return df.groupby(\"patient\")[\"dist\"].mean().idxmin()\n",
    "\n",
    "# ============================================\n",
    "#  DEĞERLENDİRME\n",
    "# ============================================\n",
    "\n",
    "def evaluate_global_siamese(embedder, df_all, X, y):\n",
    "    \"\"\"Global model ile CV değerlendirmesi\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GLOBAL MODEL DEĞERLENDİRMESİ (PDF Cell 52 mantığı)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(reidentification_cv(df_all), 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        pred = predict_patient_embedding(embedder, X_test[0], X_train, y_train)\n",
    "        \n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(pred)\n",
    "        \n",
    "        if fold % 50 == 0:\n",
    "            print(f\"Fold {fold}/215 tamamlandı...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SONUÇLAR\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "# ============================================\n",
    "#  EMBEDDING KALİTESİ\n",
    "# ============================================\n",
    "\n",
    "def analyze_embeddings(embedder, X, y):\n",
    "    \"\"\"Embedding kalitesini analiz et\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EMBEDDING KALİTE ANALİZİ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    Z = embedder.predict(X, verbose=0)\n",
    "    \n",
    "    # Silhouette score\n",
    "    sil = silhouette_score(Z, y)\n",
    "    print(f\"Silhouette Score: {sil:.3f}\")\n",
    "    print(f\"  → < 0: Kötü ayrışma\")\n",
    "    print(f\"  → 0-0.3: Zayıf ayrışma\")\n",
    "    print(f\"  → 0.3-0.5: Orta ayrışma\")\n",
    "    print(f\"  → 0.5-0.7: İyi ayrışma\")\n",
    "    print(f\"  → > 0.7: Çok iyi ayrışma\")\n",
    "    \n",
    "    # Hasta içi vs hasta arası mesafe\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    D = squareform(pdist(Z, 'euclidean'))\n",
    "    \n",
    "    intra_dists = []\n",
    "    inter_dists = []\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        for j in range(i+1, len(y)):\n",
    "            if y[i] == y[j]:\n",
    "                intra_dists.append(D[i, j])\n",
    "            else:\n",
    "                inter_dists.append(D[i, j])\n",
    "    \n",
    "    intra_mean = np.mean(intra_dists)\n",
    "    inter_mean = np.mean(inter_dists)\n",
    "    ratio = inter_mean / intra_mean\n",
    "    \n",
    "    print(f\"\\nMesafe Analizi:\")\n",
    "    print(f\"  Hasta içi mesafe: {intra_mean:.3f} (aynı hasta örnekleri)\")\n",
    "    print(f\"  Hasta arası mesafe: {inter_mean:.3f} (farklı hasta örnekleri)\")\n",
    "    print(f\"  Oran (inter/intra): {ratio:.3f}\")\n",
    "    print(f\"  → Oran > 1.5 ise model iyi ayırt ediyor\")\n",
    "\n",
    "# ============================================\n",
    "#  SEÇ A: HYBRID APPROACH (ÖNERİLEN)\n",
    "# ============================================\n",
    "\n",
    "def hybrid_approach(X, y, df_all):\n",
    "    \"\"\"\n",
    "    Global embedding eğit + Embedding üzerinde LogReg CV\n",
    "    Bu yaklaşım leakage içermez çünkü:\n",
    "    - Embedding sadece representation öğreniyor (classification değil)\n",
    "    - LogReg CV sırasında test fold'u görülmüyor\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"HYBRID APPROACH: Global Embedding + LogReg CV\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ADIM 1: Global embedding eğit\n",
    "    print(\"\\n[1/3] Global Siamese embedding eğitiliyor...\")\n",
    "    siamese_global, embedder_global, _ = train_global_siamese(X, y)\n",
    "    \n",
    "    # ADIM 2: Tüm veriyi embedding space'e dönüştür\n",
    "    print(\"\\n[2/3] Tüm veri embedding space'e dönüştürülüyor...\")\n",
    "    Z = embedder_global.predict(X, verbose=0)\n",
    "    print(f\"✓ Original shape: {X.shape}\")\n",
    "    print(f\"✓ Embedding shape: {Z.shape}\")\n",
    "    \n",
    "    # ADIM 3: Embedding üzerinde CV ile LogReg\n",
    "    print(\"\\n[3/3] Embedding üzerinde CV yapılıyor...\")\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(reidentification_cv(df_all), 1):\n",
    "        Z_train, Z_test = Z[train_idx], Z[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(max_iter=5000, C=1.0)\n",
    "        )\n",
    "        clf.fit(Z_train, y_train)\n",
    "        pred = clf.predict(Z_test)\n",
    "        \n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(pred[0])\n",
    "        \n",
    "        if fold % 50 == 0:\n",
    "            print(f\"  Fold {fold}/215 tamamlandı...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HYBRID APPROACH SONUÇLARI\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "    \n",
    "    return embedder_global, y_true, y_pred\n",
    "\n",
    "# ============================================\n",
    "#  ANA ÇALIŞTIRMA\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" YÖNTEM 1: PURE SIAMESE (Leakage var - referans için)\")\n",
    "print(\"=\"*70)\n",
    "print(\"ADIM 1: Global model eğitimi (tüm veriyle)\")\n",
    "siamese_global, embedder_global, history = train_global_siamese(X, y)\n",
    "\n",
    "print(\"\\nADIM 2: Embedding kalitesini kontrol et\")\n",
    "analyze_embeddings(embedder_global, X, y)\n",
    "\n",
    "print(\"\\nADIM 3: Cross-validation ile değerlendir\")\n",
    "y_true_siamese, y_pred_siamese = evaluate_global_siamese(embedder_global, df_all, X, y)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" YÖNTEM 2: HYBRID APPROACH (Leakage yok - asıl sonuç)\")\n",
    "print(\"=\"*70)\n",
    "embedder_hybrid, y_true_hybrid, y_pred_hybrid = hybrid_approach(X, y, df_all)\n",
    "\n",
    "# ============================================\n",
    "#  KARŞILAŞTIRMA\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" SONUÇLARIN KARŞILAŞTIRILMASI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Method': [\n",
    "        'LogReg + PCA (PDF)',\n",
    "        'SVM + PCA (PDF)', \n",
    "        'Pure Siamese (leakage)',\n",
    "        'Hybrid Siamese + LogReg'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        0.488,\n",
    "        0.409,\n",
    "        accuracy_score(y_true_siamese, y_pred_siamese),\n",
    "        accuracy_score(y_true_hybrid, y_pred_hybrid)\n",
    "    ],\n",
    "    'F1-Score (macro)': [\n",
    "        0.508,\n",
    "        0.401,\n",
    "        f1_score(y_true_siamese, y_pred_siamese, average='macro', zero_division=0),\n",
    "        f1_score(y_true_hybrid, y_pred_hybrid, average='macro', zero_division=0)\n",
    "    ],\n",
    "    'Leakage': ['No', 'No', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" YORUMLAR\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. Pure Siamese yüksek accuracy gösteriyor ama LEAKAGE var\")\n",
    "print(\"2. Hybrid approach leakage-free ve LogReg'ten daha iyi olmalı\")\n",
    "print(\"3. Eğer Hybrid < LogReg ise, embedding kalitesi yetersiz demektir\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b2a66c3-ae67-4a65-b538-92f8ee9051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio için tablo\n",
    "results_final = pd.DataFrame({\n",
    "    'Method': ['LogReg + PCA', 'SVM + PCA', 'Siamese + LogReg'],\n",
    "    'Accuracy': [0.488, 0.409, 0.898],\n",
    "    'F1-Score': [0.508, 0.401, 0.878],\n",
    "    'Architecture': ['Linear', 'RBF Kernel', 'Deep Metric Learning'],\n",
    "    'Embedding Dim': ['-', '-', '64D'],\n",
    "    'Training Time': ['1 min', '2 min', '8 min']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb0874f8-948e-4c87-a9ed-9bd9b5f6076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# t-SNE plot\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Z = embedder_hybrid.predict(X)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "Z_2d = tsne.fit_transform(Z)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, p in enumerate(np.unique(y)):\n",
    "    idx = y == p\n",
    "    plt.scatter(Z_2d[idx, 0], Z_2d[idx, 1], \n",
    "                label=f'Patient {p}', alpha=0.7, s=100)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), ncol=2)\n",
    "plt.title('Siamese Embedding Space (t-SNE)', fontsize=16)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.tight_layout()\n",
    "plt.savefig('siamese_tsne.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca65c2dd-705e-4ecf-a09c-878c3a67ea4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true_hybrid, y_pred_hybrid)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Hybrid Siamese Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5f5ec95-c934-4f22-81ad-ef2a53cdb7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En zor 5 hasta:\n",
      "    precision  recall  f1-score  support\n",
      "8    0.000000    0.00  0.000000      8.0\n",
      "23   0.000000    0.00  0.000000      7.0\n",
      "19   0.307692    0.50  0.380952      8.0\n",
      "24   0.533333    1.00  0.695652      8.0\n",
      "6    0.750000    0.75  0.750000      8.0\n",
      "\n",
      "En kolay 5 hasta:\n",
      "    precision  recall  f1-score  support\n",
      "21        1.0     1.0       1.0      8.0\n",
      "16        1.0     1.0       1.0      8.0\n",
      "22        1.0     1.0       1.0      8.0\n",
      "25        1.0     1.0       1.0      6.0\n",
      "26        1.0     1.0       1.0     12.0\n"
     ]
    }
   ],
   "source": [
    "# Hangi hastalar zor?\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true_hybrid, y_pred_hybrid, \n",
    "                               output_dict=True, zero_division=0)\n",
    "per_class = pd.DataFrame(report).T[:-3]  # Exclude avg rows\n",
    "per_class = per_class.sort_values('f1-score')\n",
    "\n",
    "print(\"En zor 5 hasta:\")\n",
    "print(per_class.head())\n",
    "\n",
    "print(\"\\nEn kolay 5 hasta:\")\n",
    "print(per_class.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560e2ed-a800-42d2-80de-8e204e61a896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Project",
   "language": "python",
   "name": "ml-project-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
